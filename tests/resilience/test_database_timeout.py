"""
test_database_timeout.py
Test de Resiliencia: Sistema cuando Supabase demora o falla

Valida el comportamiento cuando la base de datos tiene problemas:
1. Timeouts en consultas/escrituras
2. Conexi√≥n intermitente
3. Rate limiting
4. Manejo de transacciones parciales
5. Estrategias de cach√© y fallback
"""

import pytest
import asyncio
import time
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, AsyncMock
import random


class DatabaseTimeoutScenario:
    """Simula diferentes escenarios de problemas con la base de datos"""
    
    def __init__(self):
        self.query_attempts = []
        self.cached_data = {}
        self.pending_writes = []
        self.connection_pool = {
            "active": 0,
            "max": 10,
            "waiting": []
        }
        
        # Configuraci√≥n de timeouts
        self.read_timeout = 5  # segundos
        self.write_timeout = 10  # segundos
        self.connection_timeout = 3  # segundos
        
    async def simulate_slow_query(self, query: str, delay: float) -> dict:
        """Simula una consulta lenta a la base de datos"""
        start_time = time.time()
        self.query_attempts.append({
            "query": query,
            "start_time": datetime.utcnow().isoformat(),
            "delay": delay
        })
        
        # Simular delay
        await asyncio.sleep(delay / 10)  # Escalar para test r√°pido
        
        elapsed = time.time() - start_time
        
        if elapsed > self.read_timeout / 10:
            raise asyncio.TimeoutError(f"Query timeout after {elapsed:.2f}s")
        
        # Retornar datos simulados
        return {
            "data": [{"id": 1, "titular": "Test Article"}],
            "query_time": elapsed
        }
    
    async def simulate_write_timeout(self, data: dict) -> dict:
        """Simula timeout en escritura"""
        self.pending_writes.append({
            "data": data,
            "timestamp": datetime.utcnow().isoformat(),
            "status": "pending"
        })
        
        # Simular escritura lenta
        write_delay = self.write_timeout + 1  # Garantizar timeout
        await asyncio.sleep(write_delay / 10)
        
        raise asyncio.TimeoutError("Write operation timeout")
    
    async def simulate_connection_pool_exhaustion(self) -> bool:
        """Simula agotamiento del pool de conexiones"""
        if self.connection_pool["active"] >= self.connection_pool["max"]:
            self.connection_pool["waiting"].append(datetime.utcnow().isoformat())
            raise Exception("Connection pool exhausted - no connections available")
        
        self.connection_pool["active"] += 1
        try:
            # Simular operaci√≥n
            await asyncio.sleep(0.1)
            return True
        finally:
            self.connection_pool["active"] -= 1
    
    def get_from_cache(self, key: str) -> dict:
        """Obtener datos del cach√© local"""
        if key in self.cached_data:
            cache_entry = self.cached_data[key]
            if datetime.utcnow() < cache_entry["expires_at"]:
                return cache_entry["data"]
        return None
    
    def save_to_cache(self, key: str, data: dict, ttl_seconds: int = 300):
        """Guardar datos en cach√© local"""
        self.cached_data[key] = {
            "data": data,
            "cached_at": datetime.utcnow(),
            "expires_at": datetime.utcnow() + timedelta(seconds=ttl_seconds)
        }


def test_database_read_timeout_with_cache_fallback():
    """Test: Sistema usa cach√© cuando hay timeout en lectura"""
    
    scenario = DatabaseTimeoutScenario()
    
    print("\n‚è±Ô∏è Test: Timeout en lectura con fallback a cach√©\n")
    
    async def dashboard_get_articles():
        """Simula Dashboard obteniendo art√≠culos"""
        cache_key = "dashboard:articles:recent"
        
        # Intentar obtener de cach√© primero
        cached = scenario.get_from_cache(cache_key)
        if cached:
            print("üì¶ Datos obtenidos del cach√©")
            return cached, "cache"
        
        # Si no hay cach√©, consultar BD
        try:
            print("üîç Consultando base de datos...")
            # Esta consulta ser√° muy lenta
            result = await scenario.simulate_slow_query(
                "SELECT * FROM articulos ORDER BY fecha DESC LIMIT 10",
                delay=8  # Mayor que timeout
            )
            
            # Guardar en cach√© si es exitoso
            scenario.save_to_cache(cache_key, result["data"])
            return result["data"], "database"
            
        except asyncio.TimeoutError:
            print("‚è±Ô∏è Timeout en consulta a base de datos")
            
            # Buscar cach√© expirado como √∫ltimo recurso
            if cache_key in scenario.cached_data:
                print("üîÑ Usando cach√© expirado como fallback")
                return scenario.cached_data[cache_key]["data"], "stale_cache"
            
            # Si no hay nada, retornar datos m√≠nimos
            print("‚ö†Ô∏è Sin cach√© disponible - retornando datos de emergencia")
            return [], "empty"
    
    # Primera consulta (sin cach√©) - deber√≠a fallar con timeout
    print("1Ô∏è‚É£ Primera consulta (sin cach√©):")
    data1, source1 = asyncio.run(dashboard_get_articles())
    assert source1 == "empty"
    assert data1 == []
    
    # Simular que ahora hay datos en cach√©
    scenario.save_to_cache("dashboard:articles:recent", 
                          [{"id": 1, "titular": "Art√≠culo en cach√©"}], 
                          ttl_seconds=60)
    
    # Segunda consulta (con cach√© v√°lido)
    print("\n2Ô∏è‚É£ Segunda consulta (con cach√© v√°lido):")
    data2, source2 = asyncio.run(dashboard_get_articles())
    assert source2 == "cache"
    assert len(data2) == 1
    
    # Simular cach√© expirado
    scenario.cached_data["dashboard:articles:recent"]["expires_at"] = datetime.utcnow() - timedelta(seconds=1)
    
    # Tercera consulta (cach√© expirado, BD con timeout)
    print("\n3Ô∏è‚É£ Tercera consulta (cach√© expirado, BD timeout):")
    data3, source3 = asyncio.run(dashboard_get_articles())
    assert source3 == "stale_cache"
    assert len(data3) == 1
    
    print("\n‚úÖ Sistema maneja timeouts con estrategia de cach√© multinivel")


def test_database_write_timeout_with_retry_queue():
    """Test: Sistema encola escrituras fallidas para reintentar"""
    
    scenario = DatabaseTimeoutScenario()
    
    print("\nüìù Test: Timeout en escritura con cola de reintentos\n")
    
    class WriteRetryQueue:
        def __init__(self):
            self.queue = []
            self.max_retries = 3
            
        async def write_with_retry(self, data: dict):
            """Intenta escribir con reintentos"""
            retry_count = 0
            
            while retry_count < self.max_retries:
                try:
                    print(f"   üì§ Intento {retry_count + 1}/{self.max_retries} de escritura...")
                    
                    if retry_count < 2:  # Primeros 2 intentos fallan
                        await scenario.simulate_write_timeout(data)
                    else:
                        # Tercer intento exitoso
                        print(f"   ‚úÖ Escritura exitosa en intento {retry_count + 1}")
                        return True
                        
                except asyncio.TimeoutError:
                    retry_count += 1
                    print(f"   ‚è±Ô∏è Timeout en escritura")
                    
                    if retry_count < self.max_retries:
                        # Agregar a cola con backoff
                        self.queue.append({
                            "data": data,
                            "retry_count": retry_count,
                            "next_retry": datetime.utcnow() + timedelta(seconds=2**retry_count)
                        })
                        print(f"   üîÑ Agregado a cola de reintentos (espera: {2**retry_count}s)")
                        await asyncio.sleep(2**retry_count / 10)  # Escalar para test
            
            return False
        
        async def process_retry_queue(self):
            """Procesa cola de reintentos"""
            processed = 0
            
            for item in self.queue:
                if datetime.utcnow() >= item["next_retry"]:
                    print(f"\nüîÑ Reintentando escritura desde cola...")
                    # En producci√≥n, esto llamar√≠a a write_with_retry
                    processed += 1
            
            return processed
    
    retry_queue = WriteRetryQueue()
    
    # Simular escritura de feedback editorial
    feedback_data = {
        "hecho_id": 123,
        "importancia_editor": 9,
        "usuario_id": "editor-001",
        "timestamp": datetime.utcnow().isoformat()
    }
    
    print("üìù Intentando guardar feedback editorial...")
    success = asyncio.run(retry_queue.write_with_retry(feedback_data))
    
    assert success is True
    assert len(scenario.pending_writes) == 2  # 2 intentos fallidos registrados
    
    print(f"\nüìä Resumen:")
    print(f"   - Intentos de escritura: {len(scenario.pending_writes) + 1}")
    print(f"   - Elementos en cola: {len(retry_queue.queue)}")
    print(f"   - Escritura final: {'Exitosa' if success else 'Fallida'}")


def test_connection_pool_management():
    """Test: Manejo del pool de conexiones bajo carga"""
    
    scenario = DatabaseTimeoutScenario()
    
    print("\nüîå Test: Gesti√≥n del pool de conexiones\n")
    
    async def simulate_concurrent_requests(num_requests: int):
        """Simula m√∫ltiples requests concurrentes"""
        results = {
            "success": 0,
            "failed": 0,
            "pool_exhausted": 0
        }
        
        async def make_request(request_id: int):
            try:
                print(f"   üì• Request {request_id}: Solicitando conexi√≥n...")
                await scenario.simulate_connection_pool_exhaustion()
                results["success"] += 1
                print(f"   ‚úÖ Request {request_id}: Completado")
            except Exception as e:
                if "pool exhausted" in str(e):
                    results["pool_exhausted"] += 1
                    print(f"   ‚ùå Request {request_id}: Pool agotado")
                else:
                    results["failed"] += 1
                    print(f"   ‚ùå Request {request_id}: Error - {e}")
        
        # Lanzar requests concurrentes
        tasks = [make_request(i) for i in range(num_requests)]
        await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    # Simular 15 requests concurrentes (pool m√°ximo = 10)
    print(f"üöÄ Lanzando 15 requests concurrentes (pool m√°ximo: {scenario.connection_pool['max']})\n")
    
    results = asyncio.run(simulate_concurrent_requests(15))
    
    print(f"\nüìä Resultados:")
    print(f"   - Exitosos: {results['success']}")
    print(f"   - Pool agotado: {results['pool_exhausted']}")
    print(f"   - Otros errores: {results['failed']}")
    print(f"   - Requests en espera: {len(scenario.connection_pool['waiting'])}")
    
    assert results["pool_exhausted"] >= 5  # Al menos 5 deber√≠an fallar por pool agotado
    assert results["success"] <= scenario.connection_pool["max"]


def test_rate_limiting_handling():
    """Test: Manejo de rate limiting de la base de datos"""
    
    print("\nüö¶ Test: Manejo de rate limiting\n")
    
    class RateLimiter:
        def __init__(self, max_requests_per_minute=60):
            self.max_requests = max_requests_per_minute
            self.requests = []
            self.blocked_until = None
            
        async def check_rate_limit(self) -> bool:
            """Verifica si se puede hacer la request"""
            now = datetime.utcnow()
            
            # Si estamos bloqueados, verificar si ya pas√≥ el tiempo
            if self.blocked_until and now < self.blocked_until:
                remaining = (self.blocked_until - now).total_seconds()
                print(f"   üõë Rate limit activo - esperar {remaining:.1f}s")
                return False
            
            # Limpiar requests antiguas (m√°s de 1 minuto)
            self.requests = [r for r in self.requests 
                           if (now - r).total_seconds() < 60]
            
            # Verificar l√≠mite
            if len(self.requests) >= self.max_requests:
                self.blocked_until = now + timedelta(seconds=30)
                print(f"   üö¶ Rate limit alcanzado ({self.max_requests} req/min)")
                return False
            
            # Agregar request actual
            self.requests.append(now)
            return True
        
        async def make_request_with_rate_limit(self, operation: str):
            """Hace request respetando rate limit"""
            if await self.check_rate_limit():
                print(f"   ‚úÖ {operation}: Permitido")
                return {"success": True, "operation": operation}
            else:
                print(f"   ‚è≥ {operation}: Bloqueado por rate limit")
                return {"success": False, "reason": "rate_limited"}
    
    rate_limiter = RateLimiter(max_requests_per_minute=5)  # L√≠mite bajo para test
    
    # Simular r√°faga de requests
    async def simulate_burst():
        results = []
        
        print("üí® Simulando r√°faga de 8 requests...\n")
        
        for i in range(8):
            result = await rate_limiter.make_request_with_rate_limit(f"Query {i+1}")
            results.append(result)
            await asyncio.sleep(0.1)  # Peque√±o delay entre requests
        
        return results
    
    results = asyncio.run(simulate_burst())
    
    # Contar √©xitos y bloqueos
    success_count = sum(1 for r in results if r["success"])
    blocked_count = sum(1 for r in results if not r["success"])
    
    print(f"\nüìä Resumen de rate limiting:")
    print(f"   - Requests exitosas: {success_count}/{len(results)}")
    print(f"   - Requests bloqueadas: {blocked_count}/{len(results)}")
    
    assert success_count == 5  # Solo 5 deber√≠an pasar (el l√≠mite)
    assert blocked_count == 3  # 3 deber√≠an ser bloqueadas


def test_transaction_rollback_on_partial_failure():
    """Test: Rollback de transacciones ante fallos parciales"""
    
    print("\nüîÑ Test: Rollback de transacciones parciales\n")
    
    class TransactionManager:
        def __init__(self):
            self.transaction_log = []
            self.committed_data = []
            
        async def execute_transaction(self, operations: list):
            """Ejecuta transacci√≥n con m√∫ltiples operaciones"""
            transaction_id = f"tx_{int(time.time())}"
            temp_changes = []
            
            print(f"üîê Iniciando transacci√≥n {transaction_id}")
            
            try:
                for i, op in enumerate(operations):
                    print(f"   üìù Operaci√≥n {i+1}/{len(operations)}: {op['type']}")
                    
                    if op.get("will_fail", False):
                        raise Exception(f"Error en operaci√≥n {i+1}")
                    
                    # Registrar cambio temporal
                    temp_changes.append({
                        "operation": op,
                        "timestamp": datetime.utcnow().isoformat()
                    })
                    
                    await asyncio.sleep(0.1)  # Simular operaci√≥n
                
                # Si todas las operaciones son exitosas, commit
                self.committed_data.extend(temp_changes)
                self.transaction_log.append({
                    "id": transaction_id,
                    "status": "committed",
                    "operations": len(operations)
                })
                print(f"   ‚úÖ Transacci√≥n {transaction_id} COMMITTED")
                return True
                
            except Exception as e:
                # Rollback - descartar cambios temporales
                print(f"   ‚ùå Error en transacci√≥n: {e}")
                print(f"   üîÑ Ejecutando ROLLBACK...")
                
                self.transaction_log.append({
                    "id": transaction_id,
                    "status": "rolled_back",
                    "reason": str(e),
                    "changes_discarded": len(temp_changes)
                })
                
                return False
    
    manager = TransactionManager()
    
    # Caso 1: Transacci√≥n exitosa
    print("\n1Ô∏è‚É£ Transacci√≥n exitosa:")
    operations_success = [
        {"type": "insert", "table": "articulos", "data": {"id": 1}},
        {"type": "insert", "table": "hechos", "data": {"id": 1}},
        {"type": "update", "table": "stats", "data": {"count": "+1"}}
    ]
    
    success1 = asyncio.run(manager.execute_transaction(operations_success))
    assert success1 is True
    assert len(manager.committed_data) == 3
    
    # Caso 2: Transacci√≥n con fallo
    print("\n2Ô∏è‚É£ Transacci√≥n con fallo en operaci√≥n 3:")
    operations_fail = [
        {"type": "insert", "table": "articulos", "data": {"id": 2}},
        {"type": "insert", "table": "hechos", "data": {"id": 2}},
        {"type": "update", "table": "invalid", "will_fail": True}
    ]
    
    success2 = asyncio.run(manager.execute_transaction(operations_fail))
    assert success2 is False
    assert len(manager.committed_data) == 3  # No se agregaron los cambios fallidos
    
    print(f"\nüìä Resumen de transacciones:")
    for tx in manager.transaction_log:
        status_icon = "‚úÖ" if tx["status"] == "committed" else "‚ùå"
        print(f"   {status_icon} {tx['id']}: {tx['status']}")
        if "reason" in tx:
            print(f"      Raz√≥n: {tx['reason']}")
            print(f"      Cambios descartados: {tx['changes_discarded']}")


def test_degraded_mode_operations():
    """Test: Operaciones en modo degradado cuando BD tiene problemas"""
    
    print("\nüîß Test: Modo degradado de operaci√≥n\n")
    
    class DegradedModeManager:
        def __init__(self):
            self.mode = "normal"
            self.health_checks = []
            self.degraded_features = []
            
        async def check_database_health(self) -> dict:
            """Verifica salud de la base de datos"""
            checks = {
                "connection": random.random() > 0.3,  # 70% success
                "query_time": random.uniform(0.1, 5.0),  # 0.1-5s
                "write_success": random.random() > 0.4,  # 60% success
            }
            
            self.health_checks.append({
                "timestamp": datetime.utcnow().isoformat(),
                "checks": checks
            })
            
            # Determinar si entrar en modo degradado
            if not checks["connection"] or checks["query_time"] > 3.0:
                return {"healthy": False, "mode": "degraded", "issues": checks}
            
            return {"healthy": True, "mode": "normal", "metrics": checks}
        
        async def operate_in_degraded_mode(self):
            """Opera con funcionalidad reducida"""
            print("   ‚ö†Ô∏è Entrando en MODO DEGRADADO")
            
            self.degraded_features = [
                "‚ùå Deshabilitado: Procesamiento en tiempo real",
                "‚ùå Deshabilitado: Actualizaciones autom√°ticas",
                "‚úÖ Activo: Lectura de cach√© solamente",
                "‚úÖ Activo: Cola de escrituras pendientes",
                "‚è∏Ô∏è Pausado: An√°lisis de nuevos art√≠culos"
            ]
            
            for feature in self.degraded_features:
                print(f"      {feature}")
            
            return {
                "mode": "degraded",
                "active_features": 2,
                "disabled_features": 3
            }
    
    manager = DegradedModeManager()
    
    # Simular m√∫ltiples health checks
    print("üè• Realizando health checks de base de datos...\n")
    
    for i in range(5):
        print(f"Check {i+1}:")
        health = asyncio.run(manager.check_database_health())
        
        if health["healthy"]:
            print(f"   ‚úÖ Base de datos saludable")
            print(f"   üìä Tiempo de query: {health['metrics']['query_time']:.2f}s")
        else:
            print(f"   ‚ùå Problemas detectados")
            if health["mode"] == "degraded":
                degraded_info = asyncio.run(manager.operate_in_degraded_mode())
        
        await asyncio.sleep(0.5)
    
    # Verificar que hubo al menos un modo degradado
    degraded_count = sum(1 for hc in manager.health_checks 
                        if not hc["checks"]["connection"] or hc["checks"]["query_time"] > 3.0)
    
    print(f"\nüìä Resumen de health checks:")
    print(f"   - Total checks: {len(manager.health_checks)}")
    print(f"   - Entradas en modo degradado: {degraded_count}")
    
    assert degraded_count > 0  # Deber√≠a haber al menos un modo degradado
    
    print("\n‚úÖ Sistema capaz de operar en modo degradado cuando BD tiene problemas")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
