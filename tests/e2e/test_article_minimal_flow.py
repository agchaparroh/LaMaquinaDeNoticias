"""
test_article_minimal_flow.py
Test End-to-End: Flujo m√≠nimo de un art√≠culo desde scraping hasta dashboard

Valida el recorrido completo de un art√≠culo:
1. Scraper genera archivo .json.gz con art√≠culo
2. Connector lee archivo y env√≠a a Pipeline  
3. Pipeline procesa y almacena en Supabase
4. Dashboard consulta y muestra el art√≠culo procesado
"""

import pytest
import json
import gzip
import os
import time
from datetime import datetime
from pathlib import Path
import tempfile
import asyncio
from unittest.mock import Mock, patch, AsyncMock


class E2EArticleFlow:
    """Simula el flujo completo de un art√≠culo a trav√©s del sistema"""
    
    def __init__(self):
        self.article_data = {
            "url": "https://example.com/e2e-test-minimal",
            "titular": "Noticia de prueba E2E m√≠nima",
            "medio": "Test E2E News",
            "pais_publicacion": "AR",
            "tipo_medio": "digital",
            "fecha_publicacion": datetime.utcnow().isoformat(),
            "contenido_texto": "Este es un contenido de prueba para el test E2E que debe tener m√°s de 50 caracteres para cumplir validaciones.",
            "contenido_html": "<p>Este es un contenido HTML de prueba para el test E2E</p>",
            "autor": "Test Author E2E",
            "seccion": "Tecnolog√≠a",
            "etiquetas_fuente": ["test", "e2e", "automatizaci√≥n"],
            "es_opinion": False,
            "es_oficial": False,
            "fecha_recopilacion": datetime.utcnow().isoformat()
        }
        self.scraped_file_path = None
        self.pipeline_response = None
        self.db_article_id = None
        self.dashboard_data = None
    
    def scraper_generate_file(self, output_dir: str) -> str:
        """Simula Scraper generando archivo .json.gz"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"articulos_{timestamp}_e2e_test.json.gz"
        filepath = os.path.join(output_dir, filename)
        
        with gzip.open(filepath, 'wt', encoding='utf-8') as f:
            json.dump([self.article_data], f, ensure_ascii=False, indent=2)
        
        self.scraped_file_path = filepath
        return filepath
    
    def connector_read_and_send(self) -> dict:
        """Simula Connector leyendo archivo y enviando a Pipeline"""
        # Leer archivo generado
        with gzip.open(self.scraped_file_path, 'rt', encoding='utf-8') as f:
            articles = json.loads(f.read())
        
        assert len(articles) == 1
        article = articles[0]
        
        # Validaciones del Connector
        assert len(article['contenido_texto']) >= 50
        assert article['url']
        assert article['titular']
        assert article['medio']
        
        # Simular env√≠o a Pipeline
        payload = {"articulo": article}
        
        # Simular respuesta del Pipeline
        self.pipeline_response = {
            "status": 202,
            "success": True,
            "fragmento_id": "frag-e2e-test-123",
            "message": "Art√≠culo aceptado para procesamiento"
        }
        
        return self.pipeline_response
    
    def pipeline_process_article(self) -> dict:
        """Simula Pipeline procesando art√≠culo"""
        # Pipeline extrae hechos del art√≠culo
        hechos_extraidos = [
            {
                "contenido": "Se realiz√≥ prueba E2E del sistema",
                "tipo": "declaracion",
                "importancia_automatica": 7,
                "confianza_extraccion": 0.85
            },
            {
                "contenido": "El test valid√≥ el flujo completo",
                "tipo": "accion",
                "importancia_automatica": 8,
                "confianza_extraccion": 0.90
            }
        ]
        
        # Simular almacenamiento en Supabase
        self.db_article_id = "art-e2e-" + str(int(time.time()))
        
        db_record = {
            "id": self.db_article_id,
            "url": self.article_data["url"],
            "titular": self.article_data["titular"],
            "medio": self.article_data["medio"],
            "contenido_texto": self.article_data["contenido_texto"],
            "hechos": hechos_extraidos,
            "estado_procesamiento": "completado",
            "fecha_procesamiento": datetime.utcnow().isoformat()
        }
        
        return db_record
    
    def dashboard_query_article(self) -> dict:
        """Simula Dashboard consultando art√≠culo procesado"""
        # Dashboard consulta por ID o por filtros
        query_response = {
            "articulo": {
                "id": self.db_article_id,
                "titular": self.article_data["titular"],
                "medio": self.article_data["medio"],
                "fecha_publicacion": self.article_data["fecha_publicacion"],
                "hechos_count": 2,
                "hechos": [
                    {
                        "id": "hecho-1",
                        "contenido": "Se realiz√≥ prueba E2E del sistema",
                        "importancia_automatica": 7,
                        "importancia_editor": None  # Sin editar a√∫n
                    },
                    {
                        "id": "hecho-2", 
                        "contenido": "El test valid√≥ el flujo completo",
                        "importancia_automatica": 8,
                        "importancia_editor": None
                    }
                ],
                "estado": "disponible_para_revision"
            }
        }
        
        self.dashboard_data = query_response
        return query_response


def test_article_minimal_flow():
    """Test E2E: Un art√≠culo completa todo el flujo del sistema"""
    
    # GIVEN: Sistema desplegado y funcionando
    flow = E2EArticleFlow()
    
    with tempfile.TemporaryDirectory() as temp_dir:
        print("\nüöÄ Iniciando test E2E de flujo m√≠nimo de art√≠culo\n")
        
        # WHEN: El flujo completo se ejecuta
        
        # 1. Scraper genera archivo
        print("1Ô∏è‚É£ SCRAPER: Generando archivo .json.gz...")
        scraped_file = flow.scraper_generate_file(temp_dir)
        assert os.path.exists(scraped_file)
        print(f"   ‚úÖ Archivo generado: {os.path.basename(scraped_file)}")
        
        # 2. Connector procesa y env√≠a
        print("\n2Ô∏è‚É£ CONNECTOR: Leyendo archivo y enviando a Pipeline...")
        pipeline_response = flow.connector_read_and_send()
        assert pipeline_response["status"] == 202
        assert pipeline_response["success"] is True
        print(f"   ‚úÖ Pipeline acept√≥ art√≠culo: {pipeline_response['fragmento_id']}")
        
        # 3. Pipeline procesa
        print("\n3Ô∏è‚É£ PIPELINE: Procesando art√≠culo y extrayendo hechos...")
        db_record = flow.pipeline_process_article()
        assert db_record["estado_procesamiento"] == "completado"
        assert len(db_record["hechos"]) > 0
        print(f"   ‚úÖ Art√≠culo procesado con {len(db_record['hechos'])} hechos extra√≠dos")
        print(f"   üìä ID en base de datos: {db_record['id']}")
        
        # 4. Dashboard consulta
        print("\n4Ô∏è‚É£ DASHBOARD: Consultando art√≠culo procesado...")
        dashboard_data = flow.dashboard_query_article()
        assert dashboard_data["articulo"]["id"] == db_record["id"]
        assert dashboard_data["articulo"]["estado"] == "disponible_para_revision"
        print(f"   ‚úÖ Art√≠culo disponible en dashboard")
        print(f"   üìù Hechos listos para revisi√≥n editorial: {dashboard_data['articulo']['hechos_count']}")
        
        # THEN: Validar el flujo completo
        print("\n‚úÖ FLUJO COMPLETO EXITOSO:")
        print(f"   - Art√≠culo: '{flow.article_data['titular']}'")
        print(f"   - Recorrido: Scraper ‚Üí Connector ‚Üí Pipeline ‚Üí Database ‚Üí Dashboard")
        print(f"   - Hechos extra√≠dos: {len(dashboard_data['articulo']['hechos'])}")
        print(f"   - Estado final: {dashboard_data['articulo']['estado']}")
        
        # Verificaciones adicionales
        assert flow.article_data["url"] == dashboard_data["articulo"]["titular"]  # T√≠tulo se preserva
        assert all(h["importancia_editor"] is None for h in dashboard_data["articulo"]["hechos"])  # Sin editar a√∫n


def test_article_minimal_flow_with_timing():
    """Test E2E con medici√≥n de tiempos para detectar cuellos de botella"""
    
    flow = E2EArticleFlow()
    timings = {}
    
    with tempfile.TemporaryDirectory() as temp_dir:
        print("\n‚è±Ô∏è Test E2E con medici√≥n de tiempos\n")
        
        # Scraper
        start = time.time()
        flow.scraper_generate_file(temp_dir)
        timings["scraper"] = time.time() - start
        
        # Connector  
        start = time.time()
        flow.connector_read_and_send()
        timings["connector"] = time.time() - start
        
        # Pipeline
        start = time.time() 
        flow.pipeline_process_article()
        timings["pipeline"] = time.time() - start
        
        # Dashboard
        start = time.time()
        flow.dashboard_query_article()
        timings["dashboard"] = time.time() - start
        
        # Reporte de tiempos
        total_time = sum(timings.values())
        print("\nüìä An√°lisis de tiempos:")
        for stage, duration in timings.items():
            percentage = (duration / total_time) * 100
            print(f"   {stage.upper()}: {duration:.3f}s ({percentage:.1f}%)")
        print(f"\n   TOTAL: {total_time:.3f}s")
        
        # Alertar si alguna etapa toma m√°s del 50% del tiempo
        for stage, duration in timings.items():
            percentage = (duration / total_time) * 100
            assert percentage < 50, f"‚ö†Ô∏è {stage} tom√≥ {percentage:.1f}% del tiempo total"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
