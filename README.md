# La MÃ¡quina de Noticias

Sistema modular para recopilaciÃ³n, procesamiento y anÃ¡lisis de noticias. Herramienta diseÃ±ada para periodistas que permite extracciÃ³n de conocimiento estructurado desde grandes volÃºmenes de texto.

## ğŸ³ Arquitectura de Contenedores Docker

**Cada mÃ³dulo es un contenedor Docker independiente y autÃ³nomo, conectado mediante APIs.**

### Principios de DiseÃ±o

- **Independencia Total:** Cada contenedor selecciona sus tecnologÃ­as Ã³ptimas
- **ComunicaciÃ³n por Red:** Intercambio Ãºnicamente por APIs REST/HTTP  
- **AutonomÃ­a de ConfiguraciÃ³n:** Variables de entorno especÃ­ficas por mÃ³dulo
- **Seguridad Uniforme:** PrÃ¡cticas consistentes (usuarios no-root, health checks)

### Ejemplos de EspecializaciÃ³n Apropiada
- `module_scraper`: Python 3.10 (Ã³ptimo para Scrapy + Playwright)
- `module_pipeline`: Python 3.9 (estable para ML + spaCy)
- `module_connector`: Worker service (procesamiento de archivos)

## ğŸ“‹ MÃ³dulos del Sistema

### Estado de ImplementaciÃ³n

- [x] module_scraper - Sistema de recopilaciÃ³n de noticias (Scrapy)
- [x] module_connector - Conector entre scraper y pipeline  
- [x] module_pipeline - Pipeline principal de procesamiento con LLMs
- [ ] module_orchestration_agent - OrquestaciÃ³n y scheduling (Prefect)
- [ ] module_maintenance_scripts - Scripts de mantenimiento
- [ ] module_chat_interface_backend - API interfaz de investigaciÃ³n
- [ ] module_chat_interface_frontend - UI interfaz de investigaciÃ³n
- [ ] module_dashboard_review_backend - API dashboard periodistas
- [ ] module_dashboard_review_frontend - UI dashboard periodistas
- [ ] module_dev_interface_backend - API herramientas desarrollo
- [ ] module_dev_interface_frontend - UI herramientas desarrollo
- [ ] nginx_reverse_proxy - Proxy reverso y balanceador

## ğŸš€ Quick Start

### Prerrequisitos
- Docker y Docker Compose
- Variables de entorno configuradas en `.env`

### EjecuciÃ³n
```bash
# Construir y ejecutar todos los servicios
docker-compose up --build

# Servicios disponibles:
# - module_pipeline: http://localhost:8003 (FastAPI server)
# - module_connector: Worker service (procesa archivos)
# - module_scraper: Scrapy crawler
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ src/                          # MÃ³dulos implementados
â”‚   â”œâ”€â”€ module_scraper/           # Web scraping (Python 3.10)
â”‚   â”œâ”€â”€ module_connector/         # Worker service (Python 3.9)
â”‚   â”œâ”€â”€ module_pipeline/          # ML processing (Python 3.9)
â”‚   â””â”€â”€ [otros mÃ³dulos]/          # Pendientes de implementaciÃ³n
â”œâ”€â”€ BaseDeDatos_SUPABASE/         # ConfiguraciÃ³n y migraciones BD
â”œâ”€â”€ docs/                         # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ Borrar/                       # Backup de cÃ³digo obsoleto
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n de servicios
â””â”€â”€ .env                          # Variables de entorno
```

## ğŸ”— ComunicaciÃ³n entre Servicios

Los contenedores se comunican usando nombres de servicios Docker:

```python
# âœ… Correcto - comunicaciÃ³n entre contenedores
PIPELINE_API_URL = "http://module_pipeline:8003"

# âŒ Incorrecto - no funciona entre contenedores  
PIPELINE_API_URL = "http://localhost:8003"
```

## ğŸ“š DocumentaciÃ³n

- `docs/filosofia_contenedores_docker.md` - Principios arquitecturales
- `BaseDeDatos_SUPABASE/` - ConfiguraciÃ³n base de datos Supabase
- `Limpieza/soluciones_implementadas.md` - Historial de problemas resueltos

## âš™ï¸ ConfiguraciÃ³n

Cada mÃ³dulo mantiene su configuraciÃ³n especÃ­fica:
- Variables compartidas: `SUPABASE_URL`, `SUPABASE_KEY`, `LOG_LEVEL`
- Variables especÃ­ficas: `PLAYWRIGHT_TIMEOUT`, `API_PORT`, `PIPELINE_API_URL`

## ğŸ›¡ï¸ Seguridad

- Variables sensibles en `.env` (excluido del repositorio)
- Usuarios no-root en todos los contenedores
- Health checks especÃ­ficos por tipo de servicio
- ComunicaciÃ³n por red interna Docker

---

**Arquitectura:** Microservicios Docker independientes con especializaciones apropiadas por dominio tecnolÃ³gico.
