# La MÃ¡quina de Noticias

**Sistema modular para recopilaciÃ³n, procesamiento y anÃ¡lisis automatizado de noticias.** Herramienta diseÃ±ada para periodistas que permite extracciÃ³n de conocimiento estructurado desde grandes volÃºmenes de texto utilizando inteligencia artificial.

## ğŸ¯ **Estado del Proyecto: MVP FUNCIONAL** âœ…

**La MÃ¡quina de Noticias** ha alcanzado un **Producto MÃ­nimo Viable (MVP)** completamente funcional con **6 mÃ³dulos implementados** que cubren el flujo completo desde recopilaciÃ³n hasta presentaciÃ³n.

> ğŸ“‹ **Ver [GOALS.md](GOALS.md)** para objetivos detallados, roadmap y lecciones aprendidas del MVP.

---

## ğŸ—ï¸ **Arquitectura MVP - Microservicios Docker**

**Cada mÃ³dulo es un contenedor Docker independiente y autÃ³nomo, conectado mediante APIs.**

```mermaid
graph TD
    A[ğŸ•·ï¸ module_scraper] --> B[ğŸ”— module_connector]
    B --> C[âš™ï¸ module_pipeline] 
    C --> D[ğŸ”§ module_dashboard_backend]
    D --> E[ğŸ“± module_dashboard_frontend]
    F[ğŸŒ nginx_reverse_proxy] --> D
    F --> E
    G[(ğŸ—„ï¸ Supabase)] <--> A
    G <--> C
    G <--> D
    H[ğŸ¤– Groq/Anthropic] <--> C
```

### **Principios de DiseÃ±o MVP**

- **Independencia Total**: Cada contenedor estÃ¡ construido en docker de forma autÃ³noma, por lo que cada uno selecciona sus tecnologÃ­as Ã³ptimas... sin crear problemas por incompatibilidad entre mÃ³dulos
- **ComunicaciÃ³n por Red**: Intercambio Ãºnicamente por APIs REST/HTTP  
- **AutonomÃ­a de ConfiguraciÃ³n**: Variables de entorno especÃ­ficas por mÃ³dulo
- **Seguridad Uniforme**: PrÃ¡cticas consistentes (usuarios no-root, health checks)

---

## ğŸ“‹ **MÃ³dulos Implementados en el MVP**

| **MÃ³dulo** | **TecnologÃ­a** | **Puerto** | **Estado** | **FunciÃ³n** |
|------------|----------------|------------|------------|-------------|
| **module_scraper** | Python 3.10 + Scrapy + Playwright | N/A | âœ… **Implementado** | RecopilaciÃ³n automÃ¡tica de noticias |
| **module_connector** | Python 3.9 + AsyncIO | N/A | âœ… **Implementado** | Conector entre scraper y pipeline |
| **module_pipeline** | Python 3.9 + FastAPI + spaCy + ML | 8003 | âœ… **Implementado** | Procesamiento con IA/LLMs |
| **module_dashboard_review_backend** | Python 3.9 + FastAPI | 8004 | âœ… **Implementado** | API backend dashboard editorial |
| **module_dashboard_review_frontend** | React 18 + TypeScript + Vite | 3001â†’80 | âœ… **Implementado** | UI dashboard para periodistas |
| **nginx_reverse_proxy** | Nginx 1.25 Alpine | 80, 443 | âœ… **Implementado** | Proxy reverso y balanceador |

### **Flujo de Datos MVP**

1. **ğŸ•·ï¸ ExtracciÃ³n**: `module_scraper` recopila noticias de fuentes web usando Scrapy + Playwright
2. **ğŸ”— Conectividad**: `module_connector` transfiere datos entre scraper y pipeline  
3. **âš™ï¸ Procesamiento**: `module_pipeline` aplica IA/ML para anÃ¡lisis con LLMs (Groq/Anthropic)
4. **ğŸ—„ï¸ Almacenamiento**: Datos estructurados almacenados en Supabase (PostgreSQL + Storage)
5. **ğŸ“± PresentaciÃ³n**: Dashboard web para periodistas accesible vÃ­a `nginx_reverse_proxy`

---

## ğŸ“ **Estructura del Proyecto MVP**

```
LaMaquinaDeNoticias/
â”œâ”€â”€ ğŸ“‹ GOALS.md                          # Objetivos y roadmap del proyecto
â”œâ”€â”€ ğŸ“‹ README.md                         # Este archivo
â”œâ”€â”€ ğŸ³ docker-compose.yml                # OrquestaciÃ³n de servicios MVP
â”œâ”€â”€ ğŸ”§ .env.example                      # Plantilla configuraciÃ³n
â”œâ”€â”€ ğŸ“¦ requirements.txt                  # Dependencias globales
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ src/                              # MÃ³dulos implementados
â”‚   â”œâ”€â”€ ğŸ•·ï¸ module_scraper/               # Web scraping (Python 3.10)
â”‚   â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                # Container scraper optimizado
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ scrapy.cfg                # ConfiguraciÃ³n Scrapy
â”‚   â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt          # Dependencias especÃ­ficas
â”‚   â”‚   â””â”€â”€ ğŸ“š README.md                 # DocumentaciÃ³n scraper
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”— module_connector/             # Worker service (Python 3.9)
â”‚   â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                # Container worker
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ src/                      # CÃ³digo fuente connector
â”‚   â”‚   â””â”€â”€ ğŸ“‹ requirements.txt          # Dependencias AsyncIO
â”‚   â”‚
â”‚   â”œâ”€â”€ âš™ï¸ module_pipeline/              # ML processing (Python 3.9)
â”‚   â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                # Container FastAPI + ML
â”‚   â”‚   â”œâ”€â”€ ğŸŒ src/                      # APIs y lÃ³gica ML
â”‚   â”‚   â”œâ”€â”€ ğŸ§ª tests/                    # Tests comprehensivos
â”‚   â”‚   â””â”€â”€ ğŸ“‹ requirements.txt          # spaCy + LLMs + FastAPI
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ module_dashboard_review_backend/  # API Backend (Python 3.9)
â”‚   â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                # Container FastAPI
â”‚   â”‚   â”œâ”€â”€ ğŸŒ src/                      # APIs dashboard
â”‚   â”‚   â”œâ”€â”€ ğŸ§ª tests/                    # Tests API
â”‚   â”‚   â””â”€â”€ ğŸ“‹ requirements.txt          # FastAPI + Supabase
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“± module_dashboard_review_frontend/ # UI Frontend (React 18)
â”‚   â”‚   â”œâ”€â”€ ğŸ³ Dockerfile                # Multi-stage: Node + Nginx
â”‚   â”‚   â”œâ”€â”€ âš›ï¸ src/                      # Componentes React + TS
â”‚   â”‚   â”œâ”€â”€ ğŸ“¦ package.json              # Dependencias Node
â”‚   â”‚   â””â”€â”€ âš™ï¸ vite.config.ts            # ConfiguraciÃ³n build
â”‚   â”‚
â”‚   â””â”€â”€ ğŸŒ nginx_reverse_proxy/          # Proxy + Load Balancer
â”‚       â”œâ”€â”€ ğŸ³ docker/Dockerfile         # Container Nginx optimizado
â”‚       â”œâ”€â”€ âš™ï¸ config/nginx.conf         # ConfiguraciÃ³n proxy
â”‚       â””â”€â”€ ğŸ“œ scripts/                  # Scripts deployment
â”‚
â”œâ”€â”€ ğŸ—„ï¸ BaseDeDatos_SUPABASE/             # ConfiguraciÃ³n BD
â”‚   â”œâ”€â”€ ğŸ“œ migrations/                   # Migraciones SQL
â”‚   â”œâ”€â”€ ğŸ“œ scripts/                      # Scripts utilidad BD
â”‚   â””â”€â”€ ğŸ“š GUIA_BD.md                    # DocumentaciÃ³n BD
â”‚
â””â”€â”€ ğŸ§ª tests/                            # Tests integraciÃ³n global
    â””â”€â”€ test_supabase_integration.py     # Tests MVP completo
```

---

### **Endpoints Principales del MVP**

| **Servicio** | **Endpoint Interno** | **Endpoint Externo** | **DocumentaciÃ³n** |
|--------------|----------------------|----------------------|-------------------|
| Pipeline API | `module_pipeline:8003` | `localhost:8003` | `/docs` |
| Dashboard API | `module_dashboard_review_backend:8004` | `localhost:8004` | `/docs` |
| Frontend UI | `module_dashboard_review_frontend:80` | `localhost` (via nginx) | N/A |

---

## âš™ï¸ **ConfiguraciÃ³n Consolidada**

### **ğŸš€ Setup RÃ¡pido (5 minutos)**

```bash
# 1. Clonar y configurar entorno
git clone <repo-url>
cd LaMaquinaDeNoticias

# 2. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales reales

# 3. Instalar dependencias globales
pip install -r requirements.txt

# 4. Configurar modelos de spaCy
python -m spacy download es_core_news_lg
python -m spacy download en_core_web_sm

# 5. Configurar Playwright
playwright install

# 6. Levantar servicios
docker-compose up -d
```

### **ğŸ“‹ Variables de Entorno Principales**

**âš ï¸ REQUERIDAS (obligatorias para funcionamiento bÃ¡sico):**
```env
# === SUPABASE (Base de datos) ===
PROJECT_URL="https://tu-proyecto.supabase.co"
SUPABASE_ANON_KEY="eyJhbG..."  # Clave anÃ³nima
SUPABASE_SERVICE_ROLE_KEY="eyJhbG..."  # Clave de servicio
SUPABASE_DB_PASSWORD="tu-password-seguro"

# === IA/LLMs (Procesamiento) ===
GROQ_API_KEY="gsk_tu-api-key"  # Requerida para module_pipeline

# === CONFIGURACIÃ“N BÃSICA ===
SCRAPER_TARGET_URLS="url1,url2,url3"  # URLs objetivo scraping
LOG_LEVEL="INFO"  # DEBUG, INFO, WARNING, ERROR
```

**ğŸ”§ OPCIONALES (funcionalidades avanzadas):**
```env
# APIs adicionales de IA
ANTHROPIC_API_KEY=""     # Claude (TaskMaster, funciones avanzadas)
OPENAI_API_KEY=""        # GPT models
PERPLEXITY_API_KEY=""    # Research capabilities

# Monitoreo y alertas
SENTRY_DSN=""            # Error tracking
SLACK_WEBHOOK=""         # Notificaciones

# ConfiguraciÃ³n de entorno
ENVIRONMENT="development"  # development, staging, production
DEBUG_MODE="false"       # Solo para desarrollo
```

### **ğŸ—‚ï¸ ConfiguraciÃ³n por MÃ³dulo**

**El proyecto utiliza configuraciÃ³n HÃBRIDA:**

- **ğŸŒ Variables Globales** (`.env` raÃ­z): Compartidas entre mÃ³dulos
  - Credenciales Supabase
  - APIs de IA (Groq, Anthropic, etc.)
  - ConfiguraciÃ³n de logging
  - URLs de comunicaciÃ³n inter-servicios

- **âš™ï¸ Variables EspecÃ­ficas** (cada `src/module_*/.env.example`):
  - **module_scraper**: ConfiguraciÃ³n Playwright, timeouts
  - **module_connector**: Directorios, polling intervals
  - **module_pipeline**: ConfiguraciÃ³n ML, modelos, lÃ­mites de contenido
  - **module_dashboard_backend**: CORS, puerto API
  - **module_dashboard_frontend**: Variables VITE_*
  - **nginx_reverse_proxy**: ConfiguraciÃ³n de proxy

**ğŸ“ JerarquÃ­a de ConfiguraciÃ³n:**
```
1. Variables globales (.env raÃ­z)          â† Compartidas
2. Variables especÃ­ficas (src/module_*/)   â† Sobrescriben si existe conflicto
3. Variables de Docker Compose             â† Runtime especÃ­fico
```

### **ğŸ“¦ Dependencias Consolidadas**

**El archivo `requirements.txt` global consolida TODAS las dependencias:**

- **âœ… Ventajas**: Versiones sincronizadas, sin conflictos
- **âš™ï¸ Uso**: `pip install -r requirements.txt` instala todo
- **ğŸ”„ SincronizaciÃ³n**: Cada mÃ³dulo mantiene su `requirements.txt` especÃ­fico

**ğŸ“Š CategorÃ­as de dependencias:**
- Frameworks web (FastAPI, Uvicorn)
- Base de datos (Supabase, PostgreSQL)
- IA/ML (Groq, spaCy, sentence-transformers)
- Web scraping (Scrapy, Playwright, BeautifulSoup)
- Testing (pytest, pytest-asyncio)
- Utilidades (tenacity, loguru, pydantic)

### **ğŸ³ Docker y Entornos**

**ConfiguraciÃ³n de entornos:**
```bash
# Desarrollo local
ENVIRONMENT=development
DEBUG_MODE=true
LOG_LEVEL=DEBUG

# Staging/Testing  
ENVIRONMENT=staging
DEBUG_MODE=false
LOG_LEVEL=INFO

# ProducciÃ³n
ENVIRONMENT=production
DEBUG_MODE=false
LOG_LEVEL=WARNING
```

**Variables Docker especÃ­ficas:**
```env
# ComunicaciÃ³n inter-servicios
PIPELINE_API_URL=http://module_pipeline:8003
DASHBOARD_API_URL=http://module_dashboard_review_backend:8004
FRONTEND_URL=http://module_dashboard_review_frontend:80
```

---

### **ğŸ” ValidaciÃ³n de ConfiguraciÃ³n**

**Verificar configuraciÃ³n bÃ¡sica:**
```bash
# Test conexiÃ³n Supabase
curl -H "apikey: $SUPABASE_ANON_KEY" "$SUPABASE_URL/rest/v1/"

# Test API Pipeline
curl http://localhost:8003/health

# Test API Dashboard
curl http://localhost:8004/health

# Test Frontend
curl http://localhost/
```

**Logs de verificaciÃ³n:**
```bash
# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs especÃ­ficos
docker-compose logs -f module_pipeline
docker-compose logs -f module_scraper
```

### **â— Troubleshooting ComÃºn**

| **Problema** | **Causa** | **SoluciÃ³n** |
|--------------|-----------|-------------|
| `ModuleNotFoundError` | Dependencias no instaladas | `pip install -r requirements.txt` |
| `Connection refused Supabase` | Credenciales incorrectas | Verificar `.env` y credenciales |
| `Groq API Error` | API key invÃ¡lida | Verificar `GROQ_API_KEY` |
| `Port already in use` | Puerto ocupado | Cambiar puertos en `docker-compose.yml` |
| `Permission denied` | Problemas Docker | `sudo docker-compose up` |

---

## ğŸ“š **DocumentaciÃ³n MVP**

| **Documento** | **PropÃ³sito** | **Audiencia** |
|---------------|---------------|---------------|
| **[GOALS.md](GOALS.md)** | Objetivos, MVP status, roadmap | Product & Development |
| **[README.md](README.md)** | Quick start y overview | Todos los usuarios |
| **src/module_*/README.md** | DocumentaciÃ³n tÃ©cnica especÃ­fica | Desarrolladores |
| **BaseDeDatos_SUPABASE/GUIA_BD.md** | Schema y configuraciÃ³n BD | Backend developers |
| **src/module_*/.env.example** | ConfiguraciÃ³n especÃ­fica por mÃ³dulo | DevOps/Deployment |
| **.env.example** | ConfiguraciÃ³n global consolidada | Administradores |