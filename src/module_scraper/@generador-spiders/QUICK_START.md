# ğŸš€ QUICK START - Generador de Spiders

## Â¿QuÃ© es esto?
Un sistema para generar **spiders especializados** que convierten secciones de medios digitales en fuentes tipo RSS, totalmente integrados con La MÃ¡quina de Noticias.

## ğŸ¯ Inicio RÃ¡pido (30 segundos)

### **1. InformaciÃ³n necesaria:**
```yaml
url_seccion: "https://elpais.com/internacional"
nombre_medio: "El PaÃ­s"
pais_publicacion: "EspaÃ±a"
tipo_medio: "diario"  # diario/agencia/revista
rss_disponible: "No"   # SÃ­/No
```

### **2. Generar spider:**
```bash
python generate_spider.py \
    --url "https://elpais.com/internacional" \
    --medio "El PaÃ­s" \
    --pais "EspaÃ±a" \
    --tipo "diario" \
    --rss "No"
```

### **3. Resultado:**
```
âœ… Spider guardado en: scraper_core/spiders/elpais_internacional_spider.py
ğŸ“„ DocumentaciÃ³n guardada en: scraper_core/spiders/elpais_internacional_README.md
```

## ğŸ“‹ Checklist RÃ¡pido

### **Antes de generar:**
- [ ] Tener URL de una secciÃ³n especÃ­fica (NO la home)
- [ ] Saber si hay RSS disponible
- [ ] Tener configuradas las variables de Supabase

### **DespuÃ©s de generar:**
- [ ] Probar con 3 artÃ­culos: `scrapy crawl nombre_spider -s CLOSESPIDER_ITEMCOUNT=3`
- [ ] Verificar que se guardan en Supabase
- [ ] Configurar cron para ejecuciÃ³n periÃ³dica

## ğŸ” Tipos de Spider

| Tiene RSS | Necesita JS | Tipo Spider | Frecuencia |
|-----------|-------------|-------------|------------|
| âœ… SÃ­ | N/A | RSS | 30 min |
| âŒ No | âŒ No | Scraping | 1 hora |
| âŒ No | âœ… SÃ­ | Playwright | 2 horas |

## ğŸ’¡ Ejemplos Comunes

### **Ejemplo 1: Medio con RSS**
```bash
python generate_spider.py \
    --url "https://www.bbc.com/mundo/topics/america_latina" \
    --medio "BBC Mundo" \
    --pais "Reino Unido" \
    --tipo "agencia" \
    --rss "SÃ­" \
    --rss-url "https://feeds.bbci.co.uk/mundo/america_latina/rss.xml"
```

### **Ejemplo 2: Medio sin RSS (HTML estÃ¡tico)**
```bash
python generate_spider.py \
    --url "https://www.clarin.com/economia" \
    --medio "ClarÃ­n" \
    --pais "Argentina" \
    --tipo "diario" \
    --rss "No"
```

### **Ejemplo 3: Medio con JavaScript**
```bash
python generate_spider.py \
    --url "https://www.infobae.com/tecno" \
    --medio "Infobae" \
    --pais "Argentina" \
    --tipo "diario" \
    --rss "No" \
    --strategy "playwright"
```

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Ver spiders disponibles
scrapy list

# Ejecutar spider
scrapy crawl nombre_spider

# Test rÃ¡pido (3 items)
scrapy crawl nombre_spider -s CLOSESPIDER_ITEMCOUNT=3

# Ver items extraÃ­dos
scrapy crawl nombre_spider -o test.json -s CLOSESPIDER_ITEMCOUNT=5

# Debug completo
scrapy crawl nombre_spider -L DEBUG

# Ver logs
tail -f logs/nombre_spider.log
```

## ğŸ“Š Verificar en Base de Datos

```sql
-- Contar artÃ­culos
SELECT COUNT(*) FROM articulos WHERE fuente = 'nombre_spider';

-- Ver Ãºltimos artÃ­culos
SELECT titular, fecha_publicacion, url 
FROM articulos 
WHERE fuente = 'nombre_spider'
ORDER BY fecha_recopilacion DESC
LIMIT 10;

-- EstadÃ­sticas
SELECT 
    COUNT(*) as total,
    COUNT(DISTINCT url) as urls_unicas,
    MIN(fecha_recopilacion) as primera_vez,
    MAX(fecha_recopilacion) as ultima_vez
FROM articulos
WHERE fuente = 'nombre_spider';
```

## ğŸš¨ Problemas Comunes

| Problema | SoluciÃ³n |
|----------|----------|
| `ImportError` | Verificar que estÃ¡s en el directorio correcto |
| Sin artÃ­culos | Revisar selectores o usar `--strategy playwright` |
| Sin deduplicaciÃ³n | Verificar que existe `crawl_state_*` |
| Sin conexiÃ³n DB | Configurar variables de entorno Supabase |

## ğŸ“… Configurar EjecuciÃ³n PeriÃ³dica

```bash
# Editar crontab
crontab -e

# Agregar lÃ­nea segÃºn tipo:
# RSS (cada 30 min)
*/30 * * * * cd /path && scrapy crawl spider_rss

# Scraping (cada hora)
0 * * * * cd /path && scrapy crawl spider_scraping

# Playwright (cada 2 horas)
0 */2 * * * cd /path && scrapy crawl spider_playwright
```

## ğŸ“š DocumentaciÃ³n Completa

- **Proceso detallado**: `MAIN_WORKFLOW.md`
- **GuÃ­a rÃ¡pida**: `GUIA_RAPIDA.md`
- **Ejemplos completos**: `EJEMPLOS_COMPLETOS.md`
- **SoluciÃ³n de errores**: `ERROR_HANDLING.md`

## âœ… ValidaciÃ³n Final

El spider generado:
1. âœ… Hereda de `BaseArticleSpider`
2. âœ… Usa `ArticuloInItem` correctamente
3. âœ… Se integra con pipelines del proyecto
4. âœ… Filtra por secciÃ³n estrictamente
5. âœ… Implementa deduplicaciÃ³n
6. âœ… Almacena en Supabase
7. âœ… Respeta rate limits

---

**ğŸ¯ Objetivo:** Convertir cualquier secciÃ³n web en un feed RSS automatizado  
**âš¡ Tiempo:** < 2 minutos para generar un spider funcional  
**ğŸš€ Resultado:** Spider production-ready integrado con el proyecto
