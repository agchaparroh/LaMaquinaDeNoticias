# ConfiguraciÃ³n del MÃ³dulo Scraper

## Archivos de ConfiguraciÃ³n Actualizados/Creados

### ğŸ“„ Archivos Nuevos Creados:

1. **`.gitignore`** - Control de versiones
2. **`docker-compose.yml`** - OrquestaciÃ³n de contenedores
3. **`config/.env`** - Variables de entorno para desarrollo
4. **`.dockerignore`** - Exclusiones optimizadas para Docker

### âš™ï¸ ConfiguraciÃ³n RÃ¡pida

#### 1. Configurar Variables de Entorno

```bash
# Copiar y editar el archivo de desarrollo
cd config/
cp .env .env.local
# Editar .env.local con tus credenciales reales de Supabase
```

#### 2. Desarrollo con Docker Compose

```bash
# Levantar contenedor de desarrollo
docker-compose --profile dev up -d scraper-dev

# Entrar al contenedor para desarrollo interactivo
docker-compose exec scraper-dev bash

# Dentro del contenedor, ejecutar spiders
scrapy crawl infobae

# Ejecutar tests
docker-compose --profile test up scraper-test
```

#### 3. Desarrollo Local (sin Docker)

```bash
# Instalar dependencias
pip install -r requirements.txt

# Instalar Playwright browsers
playwright install chromium --with-deps

# Configurar entorno
export $(cat config/.env | xargs)

# Ejecutar spider
scrapy crawl infobae
```

### ğŸ”§ Comandos Docker Ãštiles

```bash
# ConstrucciÃ³n y ejecuciÃ³n bÃ¡sica
docker-compose up --build scraper

# Solo ejecutar tests
docker-compose --profile test up --build scraper-test

# Desarrollo interactivo con volÃºmenes montados
docker-compose --profile dev up -d scraper-dev
docker-compose exec scraper-dev bash

# Ver logs
docker-compose logs -f scraper

# Limpiar
docker-compose down --volumes --remove-orphans
```

### ğŸ“‹ Estructura de Archivos de ConfiguraciÃ³n

```
module_scraper/
â”œâ”€â”€ .gitignore                    # âœ… Nuevo - Control de versiones
â”œâ”€â”€ .dockerignore                 # âœ… Actualizado - Exclusiones Docker
â”œâ”€â”€ docker-compose.yml            # âœ… Nuevo - OrquestaciÃ³n
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env                      # âœ… Nuevo - Desarrollo local
â”‚   â”œâ”€â”€ .env.test                 # âœ… Existente - Testing
â”‚   â””â”€â”€ .env.test.example         # âœ… Existente - Plantilla
â”œâ”€â”€ Dockerfile                    # âœ… Existente - ConfiguraciÃ³n container
â”œâ”€â”€ requirements.txt              # âœ… Existente - Dependencias
â””â”€â”€ scrapy.cfg                    # âœ… Existente - Config Scrapy
```

### ğŸš¨ Notas Importantes

1. **NO COMMITEAR** archivos `.env` con credenciales reales
2. **USAR** `.env.test` para testing, `.env` para desarrollo
3. **LOS VOLÃšMENES** Docker permiten hot-reload durante desarrollo
4. **LA CONFIGURACIÃ“N** es compatible con la estructura existente

### ğŸ” Seguridad

- Los archivos `.env` estÃ¡n en `.gitignore`
- Usar variables de entorno en producciÃ³n
- El `docker-compose.yml` estÃ¡ configurado para desarrollo, no producciÃ³n
- Revisar permisos en contenedores

### ğŸ“š Comandos de Desarrollo Comunes

```bash
# Listar spiders disponibles
docker-compose exec scraper-dev scrapy list

# Ejecutar spider especÃ­fico con logs debug
docker-compose exec scraper-dev scrapy crawl infobae -L DEBUG

# Ejecutar tests completos
docker-compose --profile test up scraper-test

# Shell de Scrapy para debugging
docker-compose exec scraper-dev scrapy shell "https://ejemplo.com"

# Verificar configuraciÃ³n
docker-compose exec scraper-dev scrapy check
```
