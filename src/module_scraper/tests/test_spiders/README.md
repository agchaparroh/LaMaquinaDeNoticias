# Tests de Spiders - La MÃ¡quina de Noticias

## ğŸ“‹ DescripciÃ³n

Este directorio contiene tests exhaustivos para verificar que todos los spiders del proyecto cumplen con:
1. Los estÃ¡ndares del proyecto La MÃ¡quina de Noticias
2. Las pautas establecidas por el @generador-spiders
3. El comportamiento tipo RSS artificial requerido

## ğŸ¯ Objetivo

Garantizar que todos los spiders (actuales y futuros) funcionen correctamente y cumplan con las especificaciones del sistema, facilitando la adiciÃ³n de nuevos medios sin comprometer la calidad.

## ğŸ“ Estructura

```
test_spiders/
â”œâ”€â”€ __init__.py                    # Exporta funciones principales
â”œâ”€â”€ test_universal_spider.py       # Test universal para TODOS los spiders
â”œâ”€â”€ test_generator_compliance.py   # VerificaciÃ³n de conformidad con @generador-spiders
â”œâ”€â”€ test_base_article.py          # Tests para la clase base BaseArticleSpider
â”œâ”€â”€ run_spider_tests.py           # Script para ejecutar tests fÃ¡cilmente
â””â”€â”€ README.md                     # Este archivo
```

## ğŸ§ª Tests Incluidos

### 1. **Test Universal (`test_universal_spider.py`)**

Verifica que TODOS los spiders cumplan con:
- âœ… Herencia correcta de `BaseArticleSpider`
- âœ… Atributos requeridos (`medio_nombre`, `pais`, `tipo_medio`, etc.)
- âœ… ConfiguraciÃ³n adecuada (rate limits, concurrencia, timeouts)
- âœ… Uso de pipelines correctos
- âœ… GeneraciÃ³n de items vÃ¡lidos con todos los campos
- âœ… Filtrado por secciÃ³n
- âœ… Manejo de errores
- âœ… Respeto a robots.txt

### 2. **Test de Conformidad (`test_generator_compliance.py`)**

Verifica cumplimiento especÃ­fico con @generador-spiders:
- âœ… LÃ­mites segÃºn tipo de spider (RSS/Scraping/Playwright)
- âœ… Comportamiento tipo RSS artificial
- âœ… ConfiguraciÃ³n de deduplicaciÃ³n
- âœ… Metadata requerida
- âœ… Rate limiting conservador
- âœ… Filtrado estricto de URLs
- âœ… Resilencia a errores

### 3. **Test de Base (`test_base_article.py`)**

Verifica la funcionalidad de `BaseArticleSpider`:
- âœ… ExtracciÃ³n de tÃ­tulo, contenido, fecha, autor
- âœ… Manejo de diferentes formatos HTML
- âœ… ExtracciÃ³n de datos estructurados (JSON-LD)
- âœ… ValidaciÃ³n de artÃ­culos
- âœ… RotaciÃ³n de user agents
- âœ… Logging y estadÃ­sticas

## ğŸš€ Uso

### Ejecutar Todos los Tests

```bash
# Desde el directorio module_scraper
python tests/test_spiders/run_spider_tests.py

# O usando pytest directamente
pytest tests/test_spiders/ -v
```

### Ejecutar Tests EspecÃ­ficos

```bash
# Solo tests universales
python tests/test_spiders/run_spider_tests.py --universal

# Solo tests de conformidad
python tests/test_spiders/run_spider_tests.py --compliance

# Validar un spider especÃ­fico
python tests/test_spiders/run_spider_tests.py --spider infobae

# Generar reporte completo
python tests/test_spiders/run_spider_tests.py --report
```

### Con AnÃ¡lisis de Cobertura

```bash
# Ejecutar con cobertura
python tests/test_spiders/run_spider_tests.py --coverage

# O con pytest
pytest tests/test_spiders/ --cov=scraper_core.spiders --cov-report=html
```

## ğŸ“Š InterpretaciÃ³n de Resultados

### Estados de Conformidad

- **COMPLIANT** âœ…: El spider cumple todos los requisitos (90%+ de puntuaciÃ³n)
- **MOSTLY_COMPLIANT** âš ï¸: El spider cumple la mayorÃ­a de requisitos (70-89%)
- **NON_COMPLIANT** âŒ: El spider requiere correcciones importantes (<70%)

### Ejemplo de Salida

```
=== Validando Spider: infobae_spider ===

âœ“ Herencia correcta de BaseArticleSpider
âœ“ Atributos requeridos presentes
âœ“ ConfiguraciÃ³n correcta
âœ“ Usa pipelines requeridos
âœ“ Genera items con campos requeridos
âœ“ Implementa filtrado por secciÃ³n
âœ“ Tiene deduplicaciÃ³n configurada
âœ“ Respeta lÃ­mites de rate
âœ“ Incluye metadata apropiada
âœ“ Maneja errores correctamente

Estado: COMPLIANT
PuntuaciÃ³n: 100/100 (100.0%)
```

## ğŸ”§ Agregar Tests para Nuevos Spiders

Los tests son **universales** y se aplican automÃ¡ticamente a todos los spiders. Al crear un nuevo spider que herede de `BaseArticleSpider`, serÃ¡ testeado automÃ¡ticamente.

### Requisitos para Pasar los Tests

1. **Heredar de BaseArticleSpider**
   ```python
   class MiNuevoSpider(BaseArticleSpider):
   ```

2. **Definir atributos requeridos**
   ```python
   medio_nombre = 'Mi Medio'
   pais = 'Argentina'
   tipo_medio = 'diario'
   target_section = 'economia'
   ```

3. **ConfiguraciÃ³n apropiada**
   ```python
   custom_settings = {
       **BaseArticleSpider.custom_settings,
       'DOWNLOAD_DELAY': 3.0,
       'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
       'CLOSESPIDER_ITEMCOUNT': 30,
       # etc...
   }
   ```

4. **Implementar mÃ©todos requeridos**
   - `parse()` o `parse_feed()` para RSS
   - `parse_article()` que retorne `ArticuloInItem`
   - `_is_section_article()` para filtrado

## ğŸ› Debugging de Fallos

### Si un spider falla los tests:

1. **Revisar el mensaje de error**
   ```bash
   AssertionError: mi_spider debe heredar de BaseArticleSpider
   ```

2. **Ejecutar validaciÃ³n especÃ­fica**
   ```bash
   python tests/test_spiders/run_spider_tests.py --spider mi_spider
   ```

3. **Verificar en cÃ³digo**
   ```python
   from tests.test_spiders import validate_spider
   from scraper_core.spiders.mi_spider import MiSpider
   
   validate_spider(MiSpider)
   ```

## ğŸ“ˆ MÃ©tricas de Calidad

Los tests verifican mÃ¡s de **20 aspectos** de cada spider:

- Estructura y herencia
- ConfiguraciÃ³n y settings
- GeneraciÃ³n de items
- Manejo de errores
- Comportamiento tipo RSS
- Filtrado y deduplicaciÃ³n
- Rate limiting
- Metadata y documentaciÃ³n

## ğŸ”„ IntegraciÃ³n Continua

Estos tests deben ejecutarse:
- Antes de cada commit
- En el pipeline de CI/CD
- DespuÃ©s de generar nuevos spiders
- PeriÃ³dicamente para detectar regresiones

## ğŸ“š DocumentaciÃ³n Relacionada

- [Generador de Spiders](../../@generador-spiders/README.md)
- [BaseArticleSpider](../../scraper_core/spiders/base/README.md)
- [GuÃ­a de Desarrollo](../../docs/development/)

## â“ FAQ

**P: Â¿Por quÃ© mi spider pasa los tests pero no funciona en producciÃ³n?**
R: Los tests verifican estructura y configuraciÃ³n, pero no conexiÃ³n real. Prueba el spider manualmente con:
```bash
scrapy crawl mi_spider -L DEBUG
```

**P: Â¿CÃ³mo excluir un spider de los tests?**
R: AÃ±Ã¡delo a `EXCLUDED_SPIDERS` en `test_universal_spider.py` (no recomendado).

**P: Â¿Los tests son lentos?**
R: Los tests no ejecutan scraping real, son rÃ¡pidos (~segundos). Si son lentos, revisa que no estÃ©s importando mÃ³dulos pesados.

---

**Ãšltima actualizaciÃ³n:** Junio 2025
**Mantenido por:** Equipo La MÃ¡quina de Noticias
