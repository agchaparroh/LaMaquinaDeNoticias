# Plan de Testing - La MÃ¡quina de Noticias

## ğŸ“‹ Resumen de Tests Implementados

### âœ… Tests Completados

#### 1. **Tests Universales de Spiders** (`test_spiders/`)
- **test_universal_spider.py**: Valida TODOS los spiders automÃ¡ticamente
  - Herencia correcta de BaseArticleSpider
  - Atributos requeridos del medio
  - ConfiguraciÃ³n tÃ©cnica (delays, timeouts)
  - GeneraciÃ³n de items vÃ¡lidos
  - Uso de pipelines correctos
  
- **test_generator_compliance.py**: Conformidad con @generador-spiders
  - LÃ­mites tÃ©cnicos por tipo de spider
  - Filtrado por secciÃ³n
  - DeduplicaciÃ³n configurada
  - Manejo de errores sin crashear

- **test_base_article.py**: Tests de la clase base
  - MÃ©todos de extracciÃ³n
  - RotaciÃ³n de user agents
  - ValidaciÃ³n de datos

#### 2. **Tests End-to-End** (`e2e/`)
- **test_complete_flow.py**: Flujo completo de extracciÃ³n
  - Spider â†’ Pipelines â†’ Storage (mockeado)
  - Procesamiento de mÃºltiples items
  - Manejo de items invÃ¡lidos
  - IntegraciÃ³n con pipelines reales

#### 3. **Tests de Middlewares** (`test_middlewares/`)
- **test_middlewares.py**: 
  - Playwright middleware (renderizado JS)
  - Rate limit monitoring
  - User agent rotation
  - DetecciÃ³n de contenido vacÃ­o
  - LÃ³gica de reintentos

#### 4. **Tests de Error Handling** (`test_error_handling/`)
- **test_error_handling.py**: Casos edge y errores
  - Errores de red (DNS, Timeout)
  - Errores HTTP (404, 500, etc.)
  - HTML malformado
  - Encoding problemÃ¡tico
  - Valores None/null
  - Unicode y emojis

#### 5. **Tests Existentes** (Ya implementados)
- **test_pipelines/**: ValidaciÃ³n y limpieza
- **test_supabase_integration.py**: IntegraciÃ³n con BD
- **unit/**: Tests unitarios de componentes

## ğŸš€ CÃ³mo Ejecutar los Tests

### Ejecutar todos los tests:
```bash
# Desde module_scraper/
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=scraper_core --cov-report=html
```

### Ejecutar categorÃ­as especÃ­ficas:
```bash
# Solo tests de spiders
pytest tests/test_spiders/ -v

# Solo tests E2E
pytest tests/e2e/ -v

# Solo tests de error handling
pytest tests/test_error_handling/ -v

# Solo tests de middlewares
pytest tests/test_middlewares/ -v
```

### Ejecutar el validador universal de spiders:
```bash
# Validar todos los spiders
python tests/test_spiders/run_spider_tests.py --report

# Validar un spider especÃ­fico
python tests/test_spiders/run_spider_tests.py --spider infobae
```

## ğŸ“Š Cobertura de Testing

### Ãreas Cubiertas:
- âœ… **Estructura de Spiders**: ValidaciÃ³n automÃ¡tica universal
- âœ… **Flujo E2E**: Desde extracciÃ³n hasta almacenamiento
- âœ… **Middlewares**: Playwright, rate limiting, user agents
- âœ… **Error Handling**: Casos edge, errores de red, HTML malo
- âœ… **Pipelines**: ValidaciÃ³n, limpieza, storage
- âœ… **IntegraciÃ³n**: Supabase, componentes del sistema

### CaracterÃ­sticas de los Tests:
- **Simples**: Sin complicaciones innecesarias
- **AutomÃ¡ticos**: Se aplican a todos los spiders nuevos
- **Con Mocks**: No requieren conexiones reales
- **RÃ¡pidos**: Ejecutan en segundos
- **Mantenibles**: FÃ¡ciles de actualizar

## ğŸ¯ FilosofÃ­a de Testing

1. **Test Universal**: Un solo test valida TODOS los spiders
2. **Sin Scheduling**: NO validamos frecuencias o cron
3. **PragmÃ¡ticos**: Tests que agregan valor real
4. **Con Mocks**: Evitamos dependencias externas
5. **Casos Reales**: Basados en problemas comunes

## ğŸ“ˆ MÃ©tricas de Calidad

Los tests verifican:
- **20+ aspectos** de cada spider automÃ¡ticamente
- **Flujo completo** desde spider hasta storage
- **Casos edge comunes** (HTML malo, errores de red)
- **IntegraciÃ³n** entre componentes

## ğŸ”„ PrÃ³ximos Pasos

Para mejorar la cobertura podrÃ­as considerar:
1. Tests de performance (si es crÃ­tico)
2. Tests de spiders especÃ­ficos con datos reales
3. Tests de integraciÃ³n con Supabase real (en CI/CD)
4. Monitoring en producciÃ³n

---

**Nota**: Todos los tests estÃ¡n diseÃ±ados para ser simples, razonables y agregar valor real al proyecto sin complicaciones innecesarias.
