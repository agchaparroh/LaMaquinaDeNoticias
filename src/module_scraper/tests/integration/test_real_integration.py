"""
Test de integraciÃ³n real simplificado.
Prueba el flujo completo con datos reales.
"""
import pytest
from scrapy.utils.test import get_crawler
from scraper_core.spiders.infobae_spider import InfobaeSpider
from scraper_core.items import ArticuloInItem


class TestRealIntegration:
    """Test de integraciÃ³n con sitio real"""
    
    @pytest.mark.integration
    def test_real_article_extraction(self):
        """Extrae un artÃ­culo real y verifica el contenido"""
        # Usaremos httpbin.org como sitio de prueba confiable
        test_url = "https://httpbin.org/html"
        extracted_items = []
        
        class TestSpider(InfobaeSpider):
            name = "test_integration"
            start_urls = [test_url]
            
            def parse(self, response):
                # Extraer contenido bÃ¡sico
                item = ArticuloInItem()
                item['url'] = response.url
                item['titular'] = response.css('h1::text').get() or 'Test Title'
                item['contenido_texto'] = ' '.join(response.css('p::text').getall())
                item['medio'] = 'httpbin'
                item['fecha_publicacion'] = '2024-01-01T00:00:00Z'
                item['pais_publicacion'] = 'Test'
                item['tipo_medio'] = 'test'
                
                extracted_items.append(item)
                yield item
        
        # Configurar y ejecutar
        settings = {
            'LOG_LEVEL': 'ERROR',
            'ITEM_PIPELINES': {
                'scraper_core.pipelines.cleaning.DataCleaningPipeline': 200,
                'scraper_core.pipelines.validation.DataValidationPipeline': 300,
            }
        }
        
        crawler = get_crawler(TestSpider, settings_dict=settings)
        crawler.crawl()
        crawler.engine.start()
        
        print(f"\nðŸŒ Test de IntegraciÃ³n Real:")
        print(f"âœ… Items extraÃ­dos: {len(extracted_items)}")
        
        if extracted_items:
            item = extracted_items[0]
            print(f"ðŸ“° TÃ­tulo: {item.get('titular', 'N/A')}")
            print(f"ðŸ“„ Contenido: {len(item.get('contenido_texto', ''))} caracteres")
            print(f"ðŸ”— URL: {item.get('url', 'N/A')}")
        
        # Verificaciones
        assert len(extracted_items) > 0, "No se extrajo ningÃºn item"
        assert extracted_items[0].get('url'), "Item sin URL"
        assert extracted_items[0].get('titular'), "Item sin tÃ­tulo"
    
    def test_pipeline_integration(self):
        """Prueba el flujo completo de pipelines"""
        from scraper_core.pipelines.cleaning import DataCleaningPipeline
        from scraper_core.pipelines.validation import DataValidationPipeline
        
        # Item con datos "sucios"
        item = ArticuloInItem()
        item['url'] = 'https://test.com/article'
        item['titular'] = '  Test Article with   spaces  '
        item['contenido_texto'] = '<p>HTML content</p>\n\n\nwith multiple\n\nlines'
        item['medio'] = 'Test Media'
        item['fecha_publicacion'] = '2024-01-01T00:00:00Z'
        item['pais_publicacion'] = 'Argentina'
        item['tipo_medio'] = 'diario'
        
        # Pipeline de limpieza
        cleaning = DataCleaningPipeline()
        cleaned_item = cleaning.process_item(item, None)
        
        # Pipeline de validaciÃ³n
        validation = DataValidationPipeline()
        final_item = validation.process_item(cleaned_item, None)
        
        print(f"\nðŸ”„ Test de Pipeline Completo:")
        print(f"âœ… TÃ­tulo original: '{item['titular']}'")
        print(f"âœ… TÃ­tulo limpio: '{final_item['titular']}'")
        print(f"âœ… Contenido procesado: {len(final_item['contenido_texto'])} chars")
        
        # Verificaciones
        assert final_item['titular'].strip() == final_item['titular'], "TÃ­tulo no fue limpiado"
        assert '<p>' not in final_item['contenido_texto'], "HTML no fue removido"
        assert '\n\n\n' not in final_item['contenido_texto'], "MÃºltiples saltos no fueron normalizados"


if __name__ == "__main__":
    test = TestRealIntegration()
    test.test_pipeline_integration()
    print("\nâœ… Test de integraciÃ³n completado")
