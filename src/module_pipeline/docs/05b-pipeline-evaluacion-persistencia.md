#  Pipeline de Procesamiento - Evaluaci贸n y Persistencia (Fases 4.5-5)

# Fases de Evaluaci贸n y Persistencia

## Fase 4.5: Evaluaci贸n de Importancia Contextual
    
**Objetivo:** Asignar un valor de importancia (escala 1-10) al hecho procesado, considerando no solo sus caracter铆sticas intr铆nsecas sino tambi茅n el contexto de tendencias informativas actual.
    
**Entrada:** Hechos procesados de la Fase 4 (con su importancia preliminar si fue asignada), metadatos del art铆culo/documento.
    
### Proceso de Evaluaci贸n

1. **Activaci贸n:** Esta fase se ejecuta despu茅s de la extracci贸n y normalizaci贸n b谩sica del hecho.
        
2. **Consulta de contexto:** Consulta la tabla `tendencias_contexto_diario` para obtener el registro de contexto de tendencias correspondiente a la fecha de procesamiento del art铆culo/fragmento.
        
3. **Aplicaci贸n del modelo ML:** Utiliza un modelo de machine learning cl谩sico (previamente entrenado y versionado por el script `importancia_model_trainer.py` de la IA Nocturna).
        
4. **Caracter铆sticas de entrada:** El modelo de ML toma como entrada un conjunto de caracter铆sticas (features):
        
   **Caracter铆sticas intr铆nsecas del hecho:**
   - Tipo de hecho
   - Pa铆s(es) asociados
   - N煤mero y tipo de entidades involucradas
   - Si es un evento futuro
   - Longitud del contenido textual
   - Importancia preliminar asignada en Fase 2 (como caracter铆stica adicional)
   
   **Caracter铆sticas contextuales (derivadas de `tendencias_contexto_diario`):**
   - Relevancia actual de las tem谩ticas del hecho
   - Si las entidades principales del hecho est谩n marcadas como 'calientes' o relevantes recientemente
   - Si el hecho se relaciona con eventos pr贸ximos de alta prioridad
   - Si se alinea con hilos narrativos actualmente activos y con alta relevancia editorial
            
5. **Predicci贸n:** El modelo predice el valor de importancia para el hecho.
        
**Salida:** Hechos con el campo importancia actualizado por el modelo de ML. Este valor se pasa a la Fase 5 para ser insertado en el campo `hechos.importancia`. Adicionalmente, este valor se registrar谩 como `importancia_asignada_sistema` en la tabla `feedback_importancia_hechos` durante la persistencia en Fase 5.
    
**Interacciones:** 
- Base de Datos (lectura de `tendencias_contexto_diario`)
- Modelo de ML (carga y predicci贸n)

## Fase 5: Ensamblaje Final y Persistencia At贸mica (ejecutar_fase_5)
    
**Objetivo:** Ensamblar todos los datos procesados en el formato correcto y persistirlos en la base de datos de forma at贸mica usando una funci贸n RPC.
    
**Entrada:** Datos del art铆culo/fragmento original, salida completa de Fase 4 y Fase 4.5 (incluyendo la importancia finalizada del hecho).
    
### Proceso de Persistencia

1. **Preparaci贸n de datos:** Se preparan los datos del hecho, incluyendo el campo importancia determinado en la Fase 4.5.
        
2. **Inicializaci贸n de campos de evaluaci贸n:** Para la inserci贸n en la tabla hechos, se inicializa:
   - `evaluacion_editorial` a `'pendiente_revision_editorial'`
   - `consenso_fuentes` a `'pendiente_analisis_fuentes'` (CP-005)
   
   > **Nota:** Los campos `confiabilidad` y `menciones_contradictorias` ya no se insertan.
        
3. **Llamada a RPC:** Se ejecuta la RPC de base de datos correspondiente:
   - `insertar_articulo_completo` para art铆culos
   - `insertar_fragmento_completo` para fragmentos
        
4. **Registro de feedback:** Dentro de la RPC, adem谩s de insertar el hecho y sus elementos relacionados, se realiza una inserci贸n en la tabla `feedback_importancia_hechos`, registrando el `hecho_id` y la `importancia_asignada_sistema` (que es el valor de importancia calculado en la Fase 4.5) (CP-004).
        
**Salida:** 
- Estado de la persistencia (茅xito/error)
- Contadores de elementos insertados/procesados
- Actualizaci贸n del estado del art铆culo/documento en la BD
- Registro de errores persistentes si falla
    
**Interacciones:** Base de Datos (llamada a RPC `insertar_articulo_completo` o `insertar_fragmento_completo`).

## Conexiones con Servicios Externos

### Modelo de Machine Learning
**Configuraci贸n:**
- `IMPORTANCE_MODEL_PATH`: Ruta al archivo del modelo de importancia
- `IMPORTANCE_MODEL_VERSION`: Versi贸n del modelo en uso

**Prop贸sito:** Asignar valores de importancia contextual a los hechos procesados bas谩ndose en caracter铆sticas intr铆nsecas y contextuales.

### Base de Datos Supabase
**Variables de entorno:**
- `SUPABASE_URL`: URL del proyecto Supabase
- `SUPABASE_KEY`: Clave an贸nima de Supabase
- `SUPABASE_SERVICE_ROLE_KEY`: Clave de rol de servicio

**Interacciones principales:**
- Lectura de `tendencias_contexto_diario` (Fase 4.5)
- Llamadas a RPCs de persistencia (Fase 5)
- Consulta de `cache_entidades` (Fase 4)

## Posibles Errores y Riesgos - Fases 4.5-5

### Fase 4.5 (Evaluaci贸n ML)
- **Errores en la carga del modelo de ML:** Archivo corrupto o incompatible
- **Fallo en la consulta a `tendencias_contexto_diario`:** Conexi贸n de BD o datos faltantes
- **Caracter铆sticas malformadas para el modelo:** Datos de entrada fuera del formato esperado
- **Predicciones fuera de rango esperado:** Valores de importancia inv谩lidos

### Fase 5 (Persistencia)
- **Errores en la ejecuci贸n de la funci贸n RPC:** Violaci贸n de constraints, timeouts, l贸gica interna de la RPC
- **Fallo al registrar errores persistentes:** Problemas en el sistema de logging de errores
- **Inconsistencias transaccionales:** Fallos parciales en la atomicidad de las operaciones

## Configuraci贸n Avanzada

### Variables de Entorno para Evaluaci贸n y Persistencia
```bash
# Configuraci贸n espec铆fica para el modelo de importancia (Fase 4.5)
IMPORTANCE_MODEL_PATH=./models/importance_model.pkl
IMPORTANCE_MODEL_VERSION=1.0

# Configuraci贸n de base de datos avanzada
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30
```

### Optimizaciones de Rendimiento
- **Pool de conexiones:** Configuraci贸n optimizada para m煤ltiples workers concurrentes
- **Batch processing:** Agrupaci贸n de operaciones de persistencia cuando sea posible
- **Retry logic:** Reintentos autom谩ticos para fallos transitorios de BD

## Adaptaci贸n para Fragmentos

La adaptaci贸n para procesar fragmentos de documentos implica:

1. **Metadatos adicionales:** Pasar `documento_id`, `fragmento_id` a trav茅s de las fases
2. **RPC espec铆fica:** Usar `insertar_fragmento_completo` en lugar de `insertar_articulo_completo`
3. **Contextualizaci贸n:** Considerar el contexto del documento original en la evaluaci贸n de importancia
4. **Agregaci贸n:** Potencial agregaci贸n de m茅tricas a nivel de documento

## Integraci贸n con el Modelo de "Tres Memorias"

### Lecturas
- **Memoria Superficial:** Consulta de `cache_entidades` para optimizaci贸n
- **Memoria Relacional:** Lectura de `tendencias_contexto_diario` para contexto

### Escrituras
- **Memoria Relacional:** Persistencia de todos los datos estructurados extra铆dos
- **Memoria Superficial:** Actualizaci贸n indirecta de cach茅s mediante triggers de BD

## M茅tricas y Monitoreo

### M茅tricas de Fase 4.5
- Tiempo de evaluaci贸n de importancia por hecho
- Distribuci贸n de valores de importancia asignados
- Tasa de 茅xito en consultas a `tendencias_contexto_diario`

### M茅tricas de Fase 5
- Tiempo de persistencia por art铆culo/fragmento
- Tasa de 茅xito de transacciones de BD
- N煤mero de elementos persistidos por categor铆a (hechos, entidades, citas, etc.)
