# ðŸ› ï¸ ConfiguraciÃ³n e Infraestructura

# EspecificaciÃ³n TÃ©cnica de ConfiguraciÃ³n e Infraestructura

## 1. Lenguajes de ProgramaciÃ³n

**Python:** Se recomienda versiÃ³n 3.8 o superior, especialmente para compatibilidad con Groq SDK.

**âš ï¸ NOTA CRÃTICA DE COMPATIBILIDAD:**
Actualmente se requiere **NumPy 1.x** (no 2.x) debido a conflictos de compatibilidad binaria con spaCy 3.8.7 y sentence-transformers 2.9.0. Las versiones especificadas en requirements.txt han sido verificadas para compatibilidad mutua.

## 2. Frameworks y LibrerÃ­as Principales

### 2.1. Framework Web y Servidor
- **FastAPI:** `0.116.2` (para la API web). Context7 ID: `/tiangolo/fastapi`
- **Uvicorn:** `0.35.1` (servidor ASGI, usar con `[standard]` para dependencias opcionales). Context7 ID: `/encode/uvicorn`

### 2.2. IntegraciÃ³n con Servicios Externos
- **Groq Python SDK (`groq`):** `0.26.0` (interacciÃ³n con la API de Groq, requiere Python 3.8+). Context7 ID: `/groq/groq-typescript`
- **Supabase Python SDK (`supabase`):** `2.15.2` (interacciÃ³n con Supabase DB y Storage). Context7 ID: `/supabase/supabase-py`

### 2.3. ValidaciÃ³n y ConfiguraciÃ³n
- **Pydantic:** `2.11.5` (validaciÃ³n de datos y configuraciÃ³n, junto con Pydantic-Settings). Context7 ID: `/pydantic/pydantic`
- **python-dotenv:** `1.1.0` (carga de variables de entorno desde archivos `.env`)

### 2.4. Logging y Utilidades
- **Loguru:** `0.7.3` (sistema de logging). Context7 ID: `/delgan/loguru`
- **json-repair:** `0.27.1` (para reparar JSON malformado proveniente de LLMs)
- **tenacity:** `9.1.2` (para reintentos robustos). Context7 ID: `/jd/tenacity`
- **python-dateutil:** `2.9.0` (parsing de fechas). Context7 ID: `/dateutil/dateutil`

### 2.5. Procesamiento de Lenguaje Natural y ML
- **spaCy:** `3.8.7` (opcional, para filtrado en Fase 1 y otras tareas NLP. Requiere descarga de modelos, ej: `python -m spacy download en_core_web_sm`). Context7 ID: `/explosion/spacy`
- **sentence-transformers:** `2.9.0` (para embeddings si se usan). Context7 ID: `/ukplab/sentence-transformers`
- **langdetect:** `1.0.9` (detecciÃ³n de idioma)
- **langid:** `1.1.6` (alternativa para detecciÃ³n de idioma). Context7 ID: `/mimino666/langdetect`
- **tiktoken:** `0.8.0` (tokenizaciÃ³n OpenAI para segmentaciÃ³n)

## 3. LibrerÃ­as Adicionales

### 3.1. Procesamiento AsÃ­ncrono
- `asyncio` (para procesamiento asÃ­ncrono y gestiÃ³n de cola/workers)
- **tenacity:** `9.1.2` (para reintentos en llamadas a Groq)
- **nest-asyncio:** `1.6.0` (compatibilidad asyncio)
- **httpx:** `0.27.2` (cliente HTTP asÃ­ncrono). Context7 ID: `/encode/httpx`

### 3.2. Utilidades de Procesamiento
- **numpy:** `>=1.21.0,<2.0.0` (procesamiento numÃ©rico, compatible con spaCy y sentence-transformers). Context7 ID: `/numpy/numpy`
- **psycopg2-binary:** `2.9.10` (driver PostgreSQL). Context7 ID: `/psycopg/psycopg2`

### 3.3. Monitoreo (Opcional)
- **sentry-sdk:** `2.29.0` (opcional, para monitorizaciÃ³n de errores)

## 4. Herramientas de Infraestructura

### 4.1. ContenizaciÃ³n y Despliegue
- **Docker** (para despliegue y contenizaciÃ³n)

### 4.2. Base de Datos
- **PostgreSQL** (base de datos subyacente)
- **pgvector** (extensiÃ³n para embeddings)
- **pg_trgm** (extensiÃ³n para similitud de texto)

## 5. Dependencias Externas

### 5.1. Otros MÃ³dulos del Sistema
- **`module_connector`:** Proporciona la entrada de artÃ­culos de noticias
- **`module_ingestion_engine`:** Proporciona la entrada de fragmentos de documentos y realiza la segmentaciÃ³n

### 5.2. Servicios Externos
- **Groq API:** Para el procesamiento LLM en Fases 1, 2, 3, 4
- **Sentry:** (opcional) Para monitorizaciÃ³n de errores en tiempo real

### 5.3. Base de Datos
- **PostgreSQL (gestionada por Supabase):** Almacenamiento principal del sistema

## 6. ConfiguraciÃ³n Completa de Variables de Entorno

```bash
# ===================================================================
# CONFIGURACIÃ“N DEL MODULE_PIPELINE - ENTORNO DE PRODUCCIÃ“N
# ===================================================================
# Este archivo contiene todas las variables de entorno necesarias para
# el funcionamiento del module_pipeline en un entorno de producciÃ³n.

# === CONFIGURACIÃ“N DEL SERVIDOR FASTAPI ===
API_HOST=0.0.0.0
API_PORT=8000
DEBUG_MODE=false

# === CONFIGURACIÃ“N DE PROCESAMIENTO ASÃNCRONO ===
WORKER_COUNT=3
QUEUE_MAX_SIZE=100

# === CONFIGURACIÃ“N DE GROQ API ===
# REQUERIDO: Obtener API key de https://console.groq.com/
GROQ_API_KEY=gsk_your_groq_api_key_here
MODEL_ID=llama-3.1-8b-instant
API_TIMEOUT=30
API_TEMPERATURE=0.1
API_MAX_TOKENS=4000
MAX_RETRIES=3
MAX_WAIT_SECONDS=60

# === CONFIGURACIÃ“N DE SUPABASE ===
# REQUERIDO: URL y claves de tu proyecto Supabase
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.your_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.your_service_role_key_here

# === LÃMITES DE CONTENIDO ===
MIN_CONTENT_LENGTH=100
MAX_CONTENT_LENGTH=50000

# === CONFIGURACIÃ“N DE DIRECTORIOS ===
PROMPTS_DIR=./prompts
METRICS_DIR=./metrics
LOG_DIR=./logs

# === CONFIGURACIÃ“N DE LOGGING ===
LOG_LEVEL=INFO
ENABLE_NOTIFICATIONS=false

# === FLAGS OPCIONALES ===
# spaCy para filtrado adicional en Fase 1 (requiere modelo descargado)
USE_SPACY_FILTER=false

# Almacenamiento de mÃ©tricas en base de datos
STORE_METRICS=true

# === CONFIGURACIÃ“N DE MONITOREO (OPCIONAL) ===
# Sentry para tracking de errores
USE_SENTRY=false
SENTRY_DSN=https://your-sentry-dsn-here@sentry.io/project

# === CONFIGURACIÃ“N AVANZADA ===
# ConfiguraciÃ³n especÃ­fica para el modelo de importancia (Fase 4.5)
IMPORTANCE_MODEL_PATH=./models/importance_model.pkl
IMPORTANCE_MODEL_VERSION=1.0

# ConfiguraciÃ³n de embeddings (si se usan)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# === CONFIGURACIÃ“N DE BASE DE DATOS AVANZADA ===
# Pool de conexiones de Supabase
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30

# === CONFIGURACIÃ“N DE RENDIMIENTO ===
# ConfiguraciÃ³n especÃ­fica del LLM para optimizaciÃ³n
LLM_BATCH_SIZE=1
LLM_CONCURRENT_REQUESTS=3

# === CONFIGURACIÃ“N DE DESARROLLO ===
# Solo para debugging - NO usar en producciÃ³n
ENABLE_DEV_ENDPOINTS=false
ENABLE_DETAILED_LOGGING=false
```

## 7. Archivos de ConfiguraciÃ³n Requeridos

### 7.1. ConfiguraciÃ³n de Entorno
- **`.env`:** Para cargar variables de entorno en desarrollo
- **`.env.example`:** Plantilla de configuraciÃ³n con valores de ejemplo

### 7.2. Prompts del LLM
Archivos de texto en `PROMPTS_DIR` conteniendo las plantillas de los prompts para el LLM:
- `Prompt_1_ filtrado.md`
- `Prompt_2_elementos_basicos.md`
- `Prompt_3_citas_datos.md`
- `Prompt_4_relaciones.md`

## 8. Requisitos del Sistema

### 8.1. Modelos de Procesamiento de Lenguaje Natural
- **Modelo spaCy:** `es_core_news_lg` descargado si `USE_SPACY_FILTER` es True
- **Comando de instalaciÃ³n:** `python -m spacy download es_core_news_lg`

### 8.2. Conectividad de Red
- **Acceso a internet:** Para conexiÃ³n con API de Groq y Supabase
- **Puertos requeridos:** Puerto configurado en `API_PORT` (default: 8000)

### 8.3. Permisos del Sistema
- **Directorio de logs:** `/var/log/maquina_noticias` con permisos de escritura
- **Archivos de configuraciÃ³n:** Permisos de lectura para archivos `.env` y prompts
- **Modelos ML:** Permisos de lectura para archivos de modelos en `./models/`

### 8.4. Base de Datos
- **Esquema configurado:** Base de datos con el esquema correcto implementado
- **Funciones RPC:** Funciones implementadas:
  - `insertar_articulo_completo`
  - `insertar_fragmento_completo`
  - `buscar_entidad_similar`
  - `buscar_posibles_duplicados_lote`

## 9. Dependencias Python (requirements.txt)

**IMPORTANTE:** NumPy 2.x causa conflictos de compatibilidad binaria con spaCy 3.8.7 y sentence-transformers 2.9.0. Se requiere NumPy 1.x hasta que haya soporte oficial.

```
# === FRAMEWORKS WEB ===
fastapi==0.116.2
uvicorn[standard]==0.35.1

# === IA/ML ===
groq==0.26.0
spacy==3.8.7
sentence-transformers==2.9.0
langid==1.1.6

# === BASE DE DATOS ===
supabase==2.15.2
psycopg2-binary==2.9.10

# === VALIDACIÃ“N Y CONFIGURACIÃ“N ===
pydantic==2.11.5
python-dotenv==1.1.0

# === HTTP CLIENTS ===
httpx==0.27.2

# === UTILIDADES ===
tenacity==9.1.2
loguru==0.7.3
python-dateutil==2.9.0

# === PROCESAMIENTO ===
numpy>=1.21.0,<2.0.0

# === TESTING ===
pytest==8.4.0
pytest-mock==3.14.1
pytest-asyncio==0.24.0

# === INFRAESTRUCTURA ===
nest-asyncio==1.6.0

# === DEPENDENCIAS ADICIONALES ===
json-repair==0.27.1
langdetect==1.0.9
tiktoken==0.8.0
sentry-sdk==2.29.0
```

## 10. ConfiguraciÃ³n del Servidor

### 10.1. InicializaciÃ³n con Uvicorn
```python
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=API_HOST,
        port=API_PORT,
        reload=DEBUG_MODE,
        access_log=True,
        log_level="info"
    )
```

### 10.2. ConfiguraciÃ³n de ProducciÃ³n
```python
# ConfiguraciÃ³n recomendada para producciÃ³n
uvicorn.run(
    "main:app",
    host="0.0.0.0",
    port=8000,
    workers=1,  # FastAPI maneja concurrencia internamente
    reload=False,
    access_log=True,
    log_level="warning"
)
```

## 11. Estructura de Directorios

```
module_pipeline/
â”œâ”€â”€ prompts/                    # Archivos de prompts externos
â”‚   â”œâ”€â”€ Prompt_1_ filtrado.md
â”‚   â”œâ”€â”€ Prompt_2_elementos_basicos.md
â”‚   â”œâ”€â”€ Prompt_3_citas_datos.md
â”‚   â””â”€â”€ Prompt_4_relaciones.md
â”œâ”€â”€ logs/                       # Directorio de logs
â”‚   â”œâ”€â”€ pipeline.log
â”‚   â”œâ”€â”€ errors/
â”‚   â””â”€â”€ api/
â”œâ”€â”€ metrics/                    # MÃ©tricas del sistema
â”œâ”€â”€ models/                     # Modelos ML (si se usan)
â”‚   â””â”€â”€ importance_model.pkl
â”œâ”€â”€ src/                        # CÃ³digo fuente
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ controller.py
â”‚   â”œâ”€â”€ phases/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/                      # Tests unitarios
â”œâ”€â”€ docker/                     # ConfiguraciÃ³n Docker
â”œâ”€â”€ .env                        # Variables de entorno
â”œâ”€â”€ .env.example               # Plantilla de configuraciÃ³n
â”œâ”€â”€ requirements.txt           # Dependencias Python
â””â”€â”€ README.md                  # DocumentaciÃ³n
```

## 12. Proceso de InstalaciÃ³n y Setup

### 12.1. InstalaciÃ³n de Dependencias
```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias (verificadas para compatibilidad)
pip install -r requirements.txt
```

**âš ï¸ IMPORTANTE:** Si tienes NumPy 2.x instalado previamente, deberÃ¡s desinstalarlo primero:
```bash
pip uninstall numpy
pip install -r requirements.txt
```

### 12.2. ConfiguraciÃ³n de spaCy (Opcional)
```bash
# Solo si USE_SPACY_FILTER=true
python -m spacy download en_core_web_sm
python -m spacy download es_core_news_lg
```

### 12.3. ConfiguraciÃ³n de Variables de Entorno
```bash
# Copiar plantilla de configuraciÃ³n
cp .env.example .env

# Editar .env con las configuraciones especÃ­ficas del entorno
nano .env
```

### 12.4. VerificaciÃ³n de Conectividad
```bash
# Verificar conexiÃ³n a Groq
curl -H "Authorization: Bearer $GROQ_API_KEY" https://api.groq.com/openai/v1/models

# Verificar conexiÃ³n a Supabase
curl -H "apikey: $SUPABASE_KEY" "$SUPABASE_URL/rest/v1/"
```

## 13. Consideraciones de Rendimiento

### 13.1. Optimizaciones Recomendadas
- **Conexiones persistentes:** ReutilizaciÃ³n de conexiones HTTP para APIs externas
- **Pool de conexiones de BD:** ConfiguraciÃ³n optimizada para mÃºltiples workers
- **CachÃ© de prompts:** Carga Ãºnica de prompts al inicializar el sistema
- **Lazy loading:** Carga diferida de modelos ML hasta su primer uso

### 13.2. ConfiguraciÃ³n de Recursos
```bash
# ConfiguraciÃ³n de memoria para modelos grandes
export PYTHONHASHSEED=0
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
```

## 14. Notas Adicionales

### 14.1. Arquitectura Modular
- El pipeline estÃ¡ diseÃ±ado para ser modular, permitiendo la modificaciÃ³n o reemplazo de fases individuales
- La calidad de la extracciÃ³n depende significativamente de la calidad de los prompts y de la capacidad del modelo LLM (`llama-3.1-8b-instant`)

### 14.2. Integraciones CrÃ­ticas
- **Fase 4:** Crucial para la integraciÃ³n con los datos existentes en la base de datos
- **Fase 5:** Garantiza la atomicidad de la inserciÃ³n de datos complejos mediante el uso de RPCs

### 14.3. Escalabilidad
- **Escalamiento horizontal:** Posibilidad de ejecutar mÃºltiples instancias del pipeline
- **Load balancing:** DistribuciÃ³n de carga entre instancias mÃºltiples
- **Monitoreo:** Herramientas de observabilidad para producciÃ³n
