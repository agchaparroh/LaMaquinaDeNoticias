# Task ID: 26
# Title: Implement monitoring and observability
# Status: done
# Dependencies: 11
# Priority: medium
# Description: Add monitoring and observability features to the application for better operational insights.
# Details:
Implement a comprehensive monitoring and observability system for the pipeline application that includes metrics collection, request tracing, enhanced logging, dashboards, and alerts. The implementation will focus on lightweight solutions that integrate with the existing codebase and provide actionable insights into application performance and health.

# Test Strategy:
Verify the monitoring system through integration tests that check endpoint responses, metric collection, alert triggering, and dashboard generation. Tests should validate that the system accurately captures pipeline performance across all phases and provides useful operational insights without significant performance overhead.

# Subtasks:
## 26.1. Implementar colector de métricas interno [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/controller.py` - Revisar métricas existentes en PipelineController 
  - `/src/utils/logging_config.py` - Entender estructura de logging para métricas
  - `/src/services/job_tracker_service.py` - Analizar tracking de jobs existente
- **📚 Documentación Context7**:
  - Sección Prometheus: "Métricas de aplicación" - Patrones de colección de métricas sin overhead
  - Sección FastAPI: "Middleware y métricas" - Integración con aplicaciones web
- **🔧 Especificaciones de implementación**:
  - Crear `src/monitoring/metrics_collector.py` que aproveche datos del controller
  - Implementar singleton para agregación de métricas del pipeline (requests/min, latencias, errores)
  - Agregar métricas por fase (tiempo fase1, éxito fase2, etc.) aprovechando logs existentes
  - Mantener métricas en memoria con ventana deslizante (últimas 24h máximo)
  - Implementar reset automático para evitar memory leaks
  - Integrar con el middleware de logging existente para capturar datos HTTP

## 26.2. Crear endpoints de observabilidad [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/main.py` - Añadir nuevos endpoints para métricas y health checks avanzados
  - `/src/controller.py` - Exponer métricas del controller vía endpoints
- **📚 Documentación Context7**:
  - Sección Prometheus: "Formato de métricas" - Estructura compatible pero simple  
  - Sección FastAPI: "Endpoints de monitoreo" - Patrones para health checks y métricas
- **🔧 Especificaciones de implementación**:
  - Endpoint `/metrics` con formato compatible Prometheus (texto plano)
  - Endpoint `/health/detailed` con checks de dependencias (Groq, Supabase)
  - Endpoint `/monitoring/dashboard` que retorne JSON con métricas agregadas
  - Endpoint `/monitoring/pipeline-status` con estado detallado de las 4 fases
  - Validar que todos los endpoints respondan en <200ms
  - Implementar caché básico para evitar recálculos frecuentes

## 26.3. Ampliar trazado de requests con contexto de fases [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/utils/logging_config.py` - Ampliar sistema de correlation IDs existente
  - `/src/pipeline/fase_1_triaje.py` - Añadir trazado específico por fase
  - `/src/pipeline/fase_2_extraccion.py` - Añadir trazado específico por fase
  - `/src/pipeline/fase_3_citas_datos.py` - Añadir trazado específico por fase  
  - `/src/pipeline/fase_4_normalizacion.py` - Añadir trazado específico por fase
- **📚 Documentación Context7**:
  - Sección OpenTelemetry: "Trazado distribuido" - Conceptos de spans y contexto
  - Sección Logging: "Correlation IDs" - Mejores prácticas para seguimiento
- **🔧 Especificaciones de implementación**:
  - Ampliar LogContext para incluir span_id por fase (phase_span_id)
  - Crear función trace_phase() que genere spans automáticamente  
  - Modificar log_phase() existente para incluir métricas de timing por span
  - Agregar trace_id a nivel de artículo y span_id a nivel de fase
  - Asegurar propagación de contexto a través de todas las fases
  - Implementar jerarquía: request_id -> article_trace_id -> phase_span_id

## 26.4. Implementar sistema básico de alertas [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/utils/logging_config.py` - Integrar alertas con sistema de logging
  - `/src/utils/error_handling.py` - Aprovechar manejo de errores para alertas
  - `/src/config.py` - Añadir configuración de umbrales de alertas
- **📚 Documentación Context7**:
  - Sección Alerting: "Umbrales y notificaciones" - Patrones de alertas simples
  - Sección Loguru: "Handlers personalizados" - Implementar handlers para alertas
- **🔧 Especificaciones de implementación**:
  - Crear `src/monitoring/alert_manager.py` con sistema de alertas basado en logs
  - Implementar alertas por: tasa de errores >10%, latencia >30s, fallos de Groq/Supabase
  - Usar handler personalizado de loguru para detectar patrones críticos
  - Crear archivo JSON local para persistir alertas (último 24h)
  - Implementar throttling para evitar spam de alertas (máximo 1 por minuto por tipo)
  - Integrar con endpoints para consultar alertas activas

## 26.5. Crear dashboard JSON para métricas clave [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/controller.py` - Extraer KPIs del pipeline
  - `/src/services/job_tracker_service.py` - Obtener métricas de jobs asíncronos
  - `/src/monitoring/metrics_collector.py` - Usar métricas recolectadas anteriormente
- **📚 Documentación Context7**:
  - Sección Dashboards: "KPIs y visualización" - Métricas relevantes para operaciones
  - Sección JSON APIs: "Estructuras de datos" - Formato estándar para dashboards
- **🔧 Especificaciones de implementación**:
  - Generar JSON con: throughput (artículos/hora), latencias p95/p99, tasa de éxito por fase
  - Incluir métricas de recursos: memoria, CPU básico, conexiones activas
  - Agregar estado de dependencias externas: Groq API health, Supabase connectivity  
  - Implementar histórico básico con granularidad horaria (últimas 24h)
  - Crear métricas de negocio: hechos extraídos/hora, entidades normalizadas/hora
  - Asegurar que el JSON sea consumible por Grafana u otras herramientas

## 26.6. Test de verificación simple [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - Archivos implementados en subtareas anteriores
  - `/tests/` - Directorio de tests existente 
- **📚 Documentación Context7**:
  - Sección Testing: "Tests de integración" - Verificar sistemas de monitoreo
- **🔧 Especificaciones de implementación**:
  - Crear script `tests/test_monitoring_system.py` que verifique:
    - Todos los endpoints de monitoreo responden correctamente
    - Métricas se generan y acumulan durante procesamiento de test
    - Sistema de alertas detecta condiciones configuradas
    - Dashboard JSON tiene estructura esperada
    - Trazado de fases funciona end-to-end
  - Script ejecutable con: `python -m pytest tests/test_monitoring_system.py -v`
  - Debe proporcionar output claro de éxito/fallo con detalles específicos
  - Incluir test de carga básico que procese 10 artículos y verifique métricas

## 26.7. Integrar con endpoints de observabilidad existentes [done]
### Dependencies: None
### Description: 
### Details:
- **📁 Documentos del repositorio**:
  - `/src/main.py` - Endpoints de observabilidad ya implementados
  - `/src/monitoring/metrics_collector.py` - Colector de métricas a implementar
- **📚 Documentación Context7**:
  - Sección Prometheus: "Integración con endpoints" - Conexión con colectores
  - Sección FastAPI: "Middleware y métricas" - Integración con aplicaciones web
- **🔧 Especificaciones de implementación**:
  - Conectar el colector de métricas interno con los endpoints ya implementados
  - Asegurar que las métricas recolectadas se reflejen en `/metrics` en formato Prometheus
  - Integrar datos del colector con `/monitoring/dashboard` para visualización JSON
  - Verificar que el estado del pipeline se refleje correctamente en `/monitoring/pipeline-status`
  - Mantener la compatibilidad con el sistema de caché implementado (TTLs configurados)
  - Asegurar que los tiempos de respuesta se mantengan por debajo de 200ms

