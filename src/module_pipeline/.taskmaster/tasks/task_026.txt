# Task ID: 26
# Title: Implement monitoring and observability
# Status: done
# Dependencies: 11
# Priority: medium
# Description: Add monitoring and observability features to the application for better operational insights.
# Details:
Implement a comprehensive monitoring and observability system for the pipeline application that includes metrics collection, request tracing, enhanced logging, dashboards, and alerts. The implementation will focus on lightweight solutions that integrate with the existing codebase and provide actionable insights into application performance and health.

# Test Strategy:
Verify the monitoring system through integration tests that check endpoint responses, metric collection, alert triggering, and dashboard generation. Tests should validate that the system accurately captures pipeline performance across all phases and provides useful operational insights without significant performance overhead.

# Subtasks:
## 26.1. Implementar colector de m茅tricas interno [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/controller.py` - Revisar m茅tricas existentes en PipelineController 
  - `/src/utils/logging_config.py` - Entender estructura de logging para m茅tricas
  - `/src/services/job_tracker_service.py` - Analizar tracking de jobs existente
- ** Documentaci贸n Context7**:
  - Secci贸n Prometheus: "M茅tricas de aplicaci贸n" - Patrones de colecci贸n de m茅tricas sin overhead
  - Secci贸n FastAPI: "Middleware y m茅tricas" - Integraci贸n con aplicaciones web
- ** Especificaciones de implementaci贸n**:
  - Crear `src/monitoring/metrics_collector.py` que aproveche datos del controller
  - Implementar singleton para agregaci贸n de m茅tricas del pipeline (requests/min, latencias, errores)
  - Agregar m茅tricas por fase (tiempo fase1, 茅xito fase2, etc.) aprovechando logs existentes
  - Mantener m茅tricas en memoria con ventana deslizante (煤ltimas 24h m谩ximo)
  - Implementar reset autom谩tico para evitar memory leaks
  - Integrar con el middleware de logging existente para capturar datos HTTP

## 26.2. Crear endpoints de observabilidad [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/main.py` - A帽adir nuevos endpoints para m茅tricas y health checks avanzados
  - `/src/controller.py` - Exponer m茅tricas del controller v铆a endpoints
- ** Documentaci贸n Context7**:
  - Secci贸n Prometheus: "Formato de m茅tricas" - Estructura compatible pero simple  
  - Secci贸n FastAPI: "Endpoints de monitoreo" - Patrones para health checks y m茅tricas
- ** Especificaciones de implementaci贸n**:
  - Endpoint `/metrics` con formato compatible Prometheus (texto plano)
  - Endpoint `/health/detailed` con checks de dependencias (Groq, Supabase)
  - Endpoint `/monitoring/dashboard` que retorne JSON con m茅tricas agregadas
  - Endpoint `/monitoring/pipeline-status` con estado detallado de las 4 fases
  - Validar que todos los endpoints respondan en <200ms
  - Implementar cach茅 b谩sico para evitar rec谩lculos frecuentes

## 26.3. Ampliar trazado de requests con contexto de fases [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/utils/logging_config.py` - Ampliar sistema de correlation IDs existente
  - `/src/pipeline/fase_1_triaje.py` - A帽adir trazado espec铆fico por fase
  - `/src/pipeline/fase_2_extraccion.py` - A帽adir trazado espec铆fico por fase
  - `/src/pipeline/fase_3_citas_datos.py` - A帽adir trazado espec铆fico por fase  
  - `/src/pipeline/fase_4_normalizacion.py` - A帽adir trazado espec铆fico por fase
- ** Documentaci贸n Context7**:
  - Secci贸n OpenTelemetry: "Trazado distribuido" - Conceptos de spans y contexto
  - Secci贸n Logging: "Correlation IDs" - Mejores pr谩cticas para seguimiento
- ** Especificaciones de implementaci贸n**:
  - Ampliar LogContext para incluir span_id por fase (phase_span_id)
  - Crear funci贸n trace_phase() que genere spans autom谩ticamente  
  - Modificar log_phase() existente para incluir m茅tricas de timing por span
  - Agregar trace_id a nivel de art铆culo y span_id a nivel de fase
  - Asegurar propagaci贸n de contexto a trav茅s de todas las fases
  - Implementar jerarqu铆a: request_id -> article_trace_id -> phase_span_id

## 26.4. Implementar sistema b谩sico de alertas [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/utils/logging_config.py` - Integrar alertas con sistema de logging
  - `/src/utils/error_handling.py` - Aprovechar manejo de errores para alertas
  - `/src/config.py` - A帽adir configuraci贸n de umbrales de alertas
- ** Documentaci贸n Context7**:
  - Secci贸n Alerting: "Umbrales y notificaciones" - Patrones de alertas simples
  - Secci贸n Loguru: "Handlers personalizados" - Implementar handlers para alertas
- ** Especificaciones de implementaci贸n**:
  - Crear `src/monitoring/alert_manager.py` con sistema de alertas basado en logs
  - Implementar alertas por: tasa de errores >10%, latencia >30s, fallos de Groq/Supabase
  - Usar handler personalizado de loguru para detectar patrones cr铆ticos
  - Crear archivo JSON local para persistir alertas (煤ltimo 24h)
  - Implementar throttling para evitar spam de alertas (m谩ximo 1 por minuto por tipo)
  - Integrar con endpoints para consultar alertas activas

## 26.5. Crear dashboard JSON para m茅tricas clave [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/controller.py` - Extraer KPIs del pipeline
  - `/src/services/job_tracker_service.py` - Obtener m茅tricas de jobs as铆ncronos
  - `/src/monitoring/metrics_collector.py` - Usar m茅tricas recolectadas anteriormente
- ** Documentaci贸n Context7**:
  - Secci贸n Dashboards: "KPIs y visualizaci贸n" - M茅tricas relevantes para operaciones
  - Secci贸n JSON APIs: "Estructuras de datos" - Formato est谩ndar para dashboards
- ** Especificaciones de implementaci贸n**:
  - Generar JSON con: throughput (art铆culos/hora), latencias p95/p99, tasa de 茅xito por fase
  - Incluir m茅tricas de recursos: memoria, CPU b谩sico, conexiones activas
  - Agregar estado de dependencias externas: Groq API health, Supabase connectivity  
  - Implementar hist贸rico b谩sico con granularidad horaria (煤ltimas 24h)
  - Crear m茅tricas de negocio: hechos extra铆dos/hora, entidades normalizadas/hora
  - Asegurar que el JSON sea consumible por Grafana u otras herramientas

## 26.6. Test de verificaci贸n simple [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - Archivos implementados en subtareas anteriores
  - `/tests/` - Directorio de tests existente 
- ** Documentaci贸n Context7**:
  - Secci贸n Testing: "Tests de integraci贸n" - Verificar sistemas de monitoreo
- ** Especificaciones de implementaci贸n**:
  - Crear script `tests/test_monitoring_system.py` que verifique:
    - Todos los endpoints de monitoreo responden correctamente
    - M茅tricas se generan y acumulan durante procesamiento de test
    - Sistema de alertas detecta condiciones configuradas
    - Dashboard JSON tiene estructura esperada
    - Trazado de fases funciona end-to-end
  - Script ejecutable con: `python -m pytest tests/test_monitoring_system.py -v`
  - Debe proporcionar output claro de 茅xito/fallo con detalles espec铆ficos
  - Incluir test de carga b谩sico que procese 10 art铆culos y verifique m茅tricas

## 26.7. Integrar con endpoints de observabilidad existentes [done]
### Dependencies: None
### Description: 
### Details:
- ** Documentos del repositorio**:
  - `/src/main.py` - Endpoints de observabilidad ya implementados
  - `/src/monitoring/metrics_collector.py` - Colector de m茅tricas a implementar
- ** Documentaci贸n Context7**:
  - Secci贸n Prometheus: "Integraci贸n con endpoints" - Conexi贸n con colectores
  - Secci贸n FastAPI: "Middleware y m茅tricas" - Integraci贸n con aplicaciones web
- ** Especificaciones de implementaci贸n**:
  - Conectar el colector de m茅tricas interno con los endpoints ya implementados
  - Asegurar que las m茅tricas recolectadas se reflejen en `/metrics` en formato Prometheus
  - Integrar datos del colector con `/monitoring/dashboard` para visualizaci贸n JSON
  - Verificar que el estado del pipeline se refleje correctamente en `/monitoring/pipeline-status`
  - Mantener la compatibilidad con el sistema de cach茅 implementado (TTLs configurados)
  - Asegurar que los tiempos de respuesta se mantengan por debajo de 200ms

