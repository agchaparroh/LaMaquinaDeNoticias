# Module Pipeline - La MÃ¡quina de Noticias

NÃºcleo de procesamiento inteligente para extracciÃ³n de informaciÃ³n estructurada de artÃ­culos de noticias y documentos extensos usando LLMs.

## ğŸ¯ PropÃ³sito

El `module_pipeline` procesa contenido textual a travÃ©s de 6 fases secuenciales para extraer:
- **Hechos estructurados** con metadata completa
- **Entidades normalizadas** (personas, organizaciones, lugares)
- **Citas textuales** atribuidas a entidades especÃ­ficas
- **Datos cuantitativos** estructurados
- **Relaciones** entre elementos extraÃ­dos

## ğŸ—ï¸ Arquitectura

```
Pipeline de 6 Fases:
1ï¸âƒ£ Preprocesamiento y Triaje
2ï¸âƒ£ ExtracciÃ³n de Elementos BÃ¡sicos
3ï¸âƒ£ ExtracciÃ³n de Citas y Datos Cuantitativos
4ï¸âƒ£ NormalizaciÃ³n, VinculaciÃ³n y Relaciones
4.5ï¸âƒ£ EvaluaciÃ³n de Importancia Contextual (ML)
5ï¸âƒ£ Ensamblaje Final y Persistencia AtÃ³mica
```

### Componentes Principales

- **API REST** (FastAPI): Endpoints `/procesar`, `/health`, `/metrics`
- **Procesamiento AsÃ­ncrono**: Cola de trabajos con workers concurrentes
- **IntegraciÃ³n LLM**: Groq API para procesamiento de lenguaje natural
- **Base de Datos**: Supabase/PostgreSQL con RPCs especializadas
- **Manejo de Errores**: Sistema robusto con fallbacks por fase

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Configurar entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar variables de entorno
```bash
cp .env.example .env
# Editar .env con tus claves de API
```

### 4. Variables mÃ­nimas requeridas
```bash
GROQ_API_KEY="gsk_your_key_here"
SUPABASE_URL="https://tu-proyecto.supabase.co"
SUPABASE_KEY="your_anon_key"
```

### 5. (Opcional) Instalar modelos spaCy
```bash
python -m spacy download es_core_news_lg
python -m spacy download en_core_web_sm
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno Clave

| Variable | Requerida | Default | DescripciÃ³n |
|----------|-----------|---------|-------------|
| `GROQ_API_KEY` | âœ… | - | API key de Groq |
| `SUPABASE_URL` | âœ… | - | URL proyecto Supabase |
| `SUPABASE_KEY` | âœ… | - | Clave anÃ³nima Supabase |
| `API_PORT` | âŒ | 8000 | Puerto del servidor |
| `WORKER_COUNT` | âŒ | 3 | Workers concurrentes |
| `LOG_LEVEL` | âŒ | INFO | Nivel de logging |

Ver `.env.example` para configuraciÃ³n completa.

## ğŸƒ Uso

### Iniciar el servidor
```bash
python main.py
```

### Procesar un artÃ­culo
```bash
curl -X POST "http://localhost:8000/procesar" \\
  -H "Content-Type: application/json" \\
  -d '{
    "articulo": {
      "medio": "Ejemplo Noticias",
      "pais_publicacion": "EspaÃ±a",
      "tipo_medio": "Diario Digital",
      "titular": "Titular de ejemplo",
      "fecha_publicacion": "2024-01-15T10:00:00Z",
      "contenido_texto": "Contenido del artÃ­culo..."
    }
  }'
```

### Verificar estado
```bash
curl http://localhost:8000/health
curl http://localhost:8000/metrics
```

## ğŸ“ Estructura del Proyecto

```
module_pipeline/
â”œâ”€â”€ src/                      # CÃ³digo fuente
â”‚   â”œâ”€â”€ models/              # Modelos Pydantic
â”‚   â”œâ”€â”€ phases/              # Fases del pipeline
â”‚   â”œâ”€â”€ services/            # Servicios externos
â”‚   â”œâ”€â”€ utils/               # Utilidades
â”‚   â””â”€â”€ api/                 # Endpoints FastAPI
â”œâ”€â”€ prompts/                 # Prompts LLM externos
â”œâ”€â”€ tests/                   # Tests unitarios
â”œâ”€â”€ docs/                    # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ logs/                    # Logs del sistema
â””â”€â”€ models/                  # Modelos ML
```

## ğŸ”„ Flujo de Procesamiento

```mermaid
graph TD
    A[ArtÃ­culo] --> B[Fase 1: Triaje]
    B --> C[Fase 2: ExtracciÃ³n BÃ¡sica]
    C --> D[Fase 3: Citas y Datos]
    D --> E[Fase 4: NormalizaciÃ³n]
    E --> F[Fase 4.5: Importancia ML]
    F --> G[Fase 5: Persistencia]
    G --> H[Supabase DB]
```

## ğŸ§ª Testing

```bash
# Ejecutar tests
pytest

# Tests especÃ­ficos
pytest tests/test_phases/
pytest tests/test_api/

# Con cobertura
pytest --cov=src tests/
```

## ğŸ“Š Monitoreo

### Health Check
- **Estado**: `healthy` | `degraded`
- **Conectividad**: Groq, Supabase
- **Workers**: Activos/Total
- **Cola**: Elementos pendientes

### MÃ©tricas
- ArtÃ­culos procesados (total, exitosos, fallidos)
- Tiempo promedio por fase
- Errores por tipo
- Throughput del sistema

## ğŸ”— IntegraciÃ³n

### Entrada desde module_connector
```json
{
  "articulo": {
    "medio": "string",
    "contenido_texto": "string",
    // ... otros campos
  }
}
```

### Salida a Supabase
- Tablas: `hechos`, `entidades`, `citas_textuales`, `datos_cuantitativos`
- RPCs: `insertar_articulo_completo`, `insertar_fragmento_completo`

## ğŸ› ï¸ Desarrollo

### Agregar nueva fase
1. Crear mÃ³dulo en `src/phases/`
2. Implementar funciÃ³n principal
3. Integrar en `controller.py`
4. AÃ±adir tests correspondientes

### Configurar nuevo servicio
1. Crear mÃ³dulo en `src/services/`
2. Implementar cliente/wrapper
3. Configurar variables de entorno
4. Documentar integraciÃ³n

## ğŸ“š DocumentaciÃ³n

- [`docs/`](docs/): DocumentaciÃ³n tÃ©cnica completa
- [API Spec](docs/02-interfaz-api.md): EspecificaciÃ³n de endpoints
- [Arquitectura](docs/01-la-maquina-de-noticias.md): VisiÃ³n general del sistema
- [ConfiguraciÃ³n](docs/08-configuracion-e-infraestructura.md): Setup detallado

## ğŸ” Troubleshooting

### Problemas comunes
- **Error Groq API**: Verificar `GROQ_API_KEY` y conectividad
- **Error Supabase**: Verificar URL y claves, RPCs implementadas
- **Memory issues**: Ajustar `WORKER_COUNT`, verificar modelos spaCy
- **JSON malformado**: Logs en `logs/errors/` con detalles

### Logs Ãºtiles
```bash
tail -f logs/pipeline.log
tail -f logs/errors/error.log
```

## ğŸ¤ ContribuciÃ³n

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

[Especificar licencia del proyecto]

---

**La MÃ¡quina de Noticias** - Transformando informaciÃ³n no estructurada en conocimiento conectado.
