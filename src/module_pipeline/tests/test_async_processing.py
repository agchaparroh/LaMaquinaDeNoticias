"""
Test de verificaci√≥n del procesamiento as√≠ncrono
===============================================

Este script verifica que el procesamiento as√≠ncrono funciona correctamente
para art√≠culos y fragmentos largos.

Ejecutar con: python tests/test_async_processing.py
"""

import sys
import asyncio
import aiohttp
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

# A√±adir el directorio src al PYTHONPATH
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# Importar utilidades
from src.utils.config import API_HOST, API_PORT

# Configuraci√≥n
API_BASE_URL = f"http://{API_HOST}:{API_PORT}"
ASYNC_PROCESSING_THRESHOLD = 10_000  # Debe coincidir con main.py


def generate_long_article(length: int = 15_000) -> Dict[str, Any]:
    """
    Genera un art√≠culo largo para pruebas de procesamiento as√≠ncrono.
    
    Args:
        length: Longitud aproximada del contenido en caracteres
        
    Returns:
        Diccionario con datos del art√≠culo
    """
    # Generar contenido largo con estructura realista
    paragraphs = []
    current_length = 0
    
    # Texto base que se repetir√° con variaciones
    base_texts = [
        "Los investigadores del Instituto Nacional de Tecnolog√≠a han desarrollado un nuevo sistema de inteligencia artificial capaz de analizar grandes vol√∫menes de datos en tiempo real. ",
        "El Dr. Carlos Mart√≠nez, director del proyecto, explic√≥ que este avance representa un hito importante en el campo del procesamiento de lenguaje natural. ",
        "Durante la conferencia de prensa, se presentaron los resultados preliminares que muestran una mejora del 45% en la precisi√≥n del an√°lisis sem√°ntico. ",
        "La implementaci√≥n de esta tecnolog√≠a podr√≠a revolucionar la forma en que las empresas procesan y analizan informaci√≥n no estructurada. ",
        "Seg√∫n las estimaciones del equipo de investigaci√≥n, el sistema podr√≠a estar disponible comercialmente en los pr√≥ximos 18 meses. ",
        "Las pruebas realizadas con datasets de diferentes industrias han demostrado la versatilidad y robustez del algoritmo desarrollado. ",
        "El proyecto ha recibido financiaci√≥n de diversas instituciones p√∫blicas y privadas interesadas en las aplicaciones pr√°cticas de esta tecnolog√≠a. ",
        "Los expertos del sector han destacado el potencial impacto que este desarrollo podr√≠a tener en √°reas como la medicina, finanzas y educaci√≥n. ",
    ]
    
    # Generar p√°rrafos hasta alcanzar la longitud deseada
    paragraph_count = 0
    while current_length < length:
        # Crear p√°rrafo combinando varios textos base
        paragraph = ""
        for i in range(3):  # 3 oraciones por p√°rrafo
            text_idx = (paragraph_count + i) % len(base_texts)
            paragraph += base_texts[text_idx]
        
        # A√±adir cita ocasional
        if paragraph_count % 4 == 0:
            paragraph += f'"Este es un momento hist√≥rico para la investigaci√≥n en IA", afirm√≥ el investigador principal. '
        
        # A√±adir datos cuantitativos ocasionales
        if paragraph_count % 3 == 0:
            paragraph += f"Los datos muestran un incremento del {20 + paragraph_count}% en la eficiencia computacional. "
        
        paragraphs.append(paragraph.strip())
        current_length += len(paragraph)
        paragraph_count += 1
    
    # Combinar todos los p√°rrafos
    contenido_texto = "\n\n".join(paragraphs)
    
    return {
        "medio": "Tech Innovation Daily",
        "pais_publicacion": "Espa√±a",
        "tipo_medio": "Digital",
        "titular": "Revolucionario avance en inteligencia artificial: nuevo sistema procesa datos con precisi√≥n sin precedentes",
        "fecha_publicacion": datetime.utcnow().isoformat() + "Z",
        "contenido_texto": contenido_texto[:length],  # Ajustar a longitud exacta
        "url": "https://techinnovation.test/ai-breakthrough-2024",
        "autor": "Mar√≠a Gonz√°lez",
        "idioma": "es",
        "seccion": "Tecnolog√≠a",
        "es_opinion": False,
        "es_oficial": False,
        "metadata": {
            "tags": ["inteligencia artificial", "tecnolog√≠a", "investigaci√≥n"],
            "test_type": "async_processing",
            "content_length": length
        }
    }


async def test_articulo_largo_async():
    """Test 1: Enviar art√≠culo largo y verificar procesamiento as√≠ncrono."""
    print("\nüß™ Test 1: Procesamiento as√≠ncrono de art√≠culo largo")
    print("-" * 60)
    
    try:
        # Generar art√≠culo largo
        articulo = generate_long_article(length=12_000)
        print(f"‚úÖ Art√≠culo generado: {len(articulo['contenido_texto'])} caracteres")
        print(f"   - T√≠tulo: {articulo['titular'][:50]}...")
        print(f"   - Medio: {articulo['medio']}")
        
        # Enviar art√≠culo v√≠a POST
        async with aiohttp.ClientSession() as session:
            print(f"\nüì§ Enviando art√≠culo a {API_BASE_URL}/procesar_articulo...")
            start_time = time.time()
            
            async with session.post(
                f"{API_BASE_URL}/procesar_articulo",
                json=articulo,
                headers={"Content-Type": "application/json"}
            ) as response:
                response_time = time.time() - start_time
                response_data = await response.json()
                
                print(f"‚úÖ Respuesta recibida en {response_time:.2f} segundos")
                print(f"   - Status code: {response.status}")
                print(f"   - Success: {response_data.get('success')}")
                print(f"   - Status: {response_data.get('status')}")
                
                # Verificar que es procesamiento as√≠ncrono
                if response_data.get('status') == 'processing':
                    print(f"‚úÖ Procesamiento as√≠ncrono confirmado")
                    print(f"   - Job ID: {response_data.get('job_id')}")
                    print(f"   - Request ID: {response_data.get('request_id')}")
                    print(f"   - Mensaje: {response_data.get('message')}")
                    
                    # Obtener informaci√≥n de tracking
                    tracking = response_data.get('tracking', {})
                    print(f"\nüìä Informaci√≥n de tracking:")
                    print(f"   - Tiempo estimado: {tracking.get('estimated_time_seconds')} segundos")
                    print(f"   - Endpoint de status: {tracking.get('check_status_endpoint')}")
                    
                    # Verificar metadata
                    metadata = response_data.get('metadata', {})
                    print(f"\nüìã Metadata:")
                    print(f"   - Longitud: {metadata.get('longitud_caracteres')} caracteres")
                    print(f"   - Es art√≠culo largo: {metadata.get('es_articulo_largo')}")
                    print(f"   - Threshold usado: {metadata.get('threshold_usado')}")
                    
                    # Verificar respuesta inmediata (debe ser < 1 segundo)
                    if response_time < 1.0:
                        print(f"\n‚úÖ Respuesta inmediata confirmada ({response_time:.2f}s < 1s)")
                    else:
                        print(f"\n‚ö†Ô∏è  Respuesta tard√≥ m√°s de lo esperado ({response_time:.2f}s)")
                    
                    return response_data.get('job_id')
                    
                else:
                    print(f"‚ùå No se detect√≥ procesamiento as√≠ncrono")
                    print(f"   - Status recibido: {response_data.get('status')}")
                    return None
                    
    except Exception as e:
        print(f"‚ùå Error en test: {e}")
        import traceback
        traceback.print_exc()
        return None


async def check_job_status(job_id: str, max_attempts: int = 30, wait_seconds: int = 2):
    """
    Consulta peri√≥dicamente el estado de un job hasta que complete.
    
    Args:
        job_id: ID del job a consultar
        max_attempts: M√°ximo n√∫mero de intentos
        wait_seconds: Segundos entre intentos
        
    Returns:
        Diccionario con el resultado final o None si falla
    """
    print(f"\nüîç Consultando estado del job: {job_id}")
    print("-" * 40)
    
    async with aiohttp.ClientSession() as session:
        for attempt in range(max_attempts):
            try:
                async with session.get(f"{API_BASE_URL}/status/{job_id}") as response:
                    if response.status == 404:
                        print(f"‚ùå Job no encontrado: {job_id}")
                        return None
                    
                    status_data = await response.json()
                    job_status = status_data.get('data', {}).get('status')
                    
                    print(f"   Intento {attempt + 1}/{max_attempts}: Status = {job_status}")
                    
                    # Si est√° completado o fall√≥, retornar resultado
                    if job_status == 'completed':
                        print(f"‚úÖ Job completado exitosamente")
                        result = status_data.get('data', {}).get('result', {})
                        print(f"   - Fragmento ID: {result.get('fragmento_id')}")
                        print(f"   - Tiempo procesamiento: {result.get('tiempo_procesamiento_segundos')}s")
                        print(f"   - Elementos extra√≠dos: {result.get('elementos_extraidos', {})}")
                        return status_data
                        
                    elif job_status == 'failed':
                        print(f"‚ùå Job fall√≥")
                        error = status_data.get('data', {}).get('error', {})
                        print(f"   - Tipo: {error.get('tipo')}")
                        print(f"   - Mensaje: {error.get('mensaje')}")
                        return status_data
                    
                    # Si sigue procesando, esperar
                    await asyncio.sleep(wait_seconds)
                    
            except Exception as e:
                print(f"   Error consultando status: {e}")
                await asyncio.sleep(wait_seconds)
    
    print(f"‚è±Ô∏è  Timeout: Job no complet√≥ despu√©s de {max_attempts * wait_seconds} segundos")
    return None


async def test_multiples_requests_concurrentes():
    """Test 2: Enviar m√∫ltiples requests concurrentes."""
    print("\nüß™ Test 2: M√∫ltiples requests concurrentes")
    print("-" * 60)
    
    try:
        # Generar 5 art√≠culos de diferentes tama√±os
        articulos = []
        sizes = [11_000, 12_000, 13_000, 14_000, 15_000]
        
        for i, size in enumerate(sizes):
            articulo = generate_long_article(length=size)
            articulo['titular'] = f"Art√≠culo concurrente #{i+1}: {articulo['titular'][:30]}..."
            articulos.append(articulo)
        
        print(f"‚úÖ Generados {len(articulos)} art√≠culos de diferentes tama√±os")
        for i, art in enumerate(articulos):
            print(f"   - Art√≠culo {i+1}: {len(art['contenido_texto'])} caracteres")
        
        # Enviar todos los art√≠culos concurrentemente
        print(f"\nüì§ Enviando {len(articulos)} art√≠culos simult√°neamente...")
        start_time = time.time()
        
        async def send_article(session, article, index):
            """Env√≠a un art√≠culo y retorna el job_id."""
            try:
                async with session.post(
                    f"{API_BASE_URL}/procesar_articulo",
                    json=article,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    data = await response.json()
                    return {
                        'index': index,
                        'job_id': data.get('job_id'),
                        'status': data.get('status'),
                        'success': data.get('success')
                    }
            except Exception as e:
                return {
                    'index': index,
                    'error': str(e)
                }
        
        # Crear tareas concurrentes
        async with aiohttp.ClientSession() as session:
            tasks = []
            for i, articulo in enumerate(articulos):
                task = send_article(session, articulo, i)
                tasks.append(task)
            
            # Ejecutar todas las tareas concurrentemente
            results = await asyncio.gather(*tasks)
        
        total_time = time.time() - start_time
        print(f"‚úÖ Todas las solicitudes enviadas en {total_time:.2f} segundos")
        
        # Verificar resultados
        job_ids = []
        for result in results:
            if 'error' in result:
                print(f"   ‚ùå Art√≠culo {result['index']+1}: Error - {result['error']}")
            else:
                print(f"   ‚úÖ Art√≠culo {result['index']+1}: Job ID = {result['job_id']}")
                if result['job_id']:
                    job_ids.append(result['job_id'])
        
        print(f"\nüìä Resumen:")
        print(f"   - Jobs creados exitosamente: {len(job_ids)}/{len(articulos)}")
        print(f"   - Tiempo total: {total_time:.2f} segundos")
        print(f"   - Tiempo promedio por request: {total_time/len(articulos):.2f} segundos")
        
        # Verificar que el sistema maneja m√∫ltiples jobs
        if len(job_ids) == len(articulos):
            print(f"\n‚úÖ El sistema maneja correctamente m√∫ltiples jobs concurrentes")
        else:
            print(f"\n‚ö†Ô∏è  Algunos jobs no se crearon correctamente")
        
        return job_ids
        
    except Exception as e:
        print(f"‚ùå Error en test: {e}")
        import traceback
        traceback.print_exc()
        return []


async def test_articulo_pequeno_sincrono():
    """Test 3: Verificar que art√≠culos peque√±os se procesan s√≠ncronamente."""
    print("\nüß™ Test 3: Procesamiento s√≠ncrono de art√≠culo peque√±o")
    print("-" * 60)
    
    try:
        # Generar art√≠culo peque√±o (menos del threshold)
        articulo = generate_long_article(length=5_000)  # Mitad del threshold
        print(f"‚úÖ Art√≠culo peque√±o generado: {len(articulo['contenido_texto'])} caracteres")
        print(f"   - Bajo el threshold de {ASYNC_PROCESSING_THRESHOLD} caracteres")
        
        # Enviar art√≠culo
        async with aiohttp.ClientSession() as session:
            print(f"\nüì§ Enviando art√≠culo peque√±o...")
            start_time = time.time()
            
            async with session.post(
                f"{API_BASE_URL}/procesar_articulo",
                json=articulo,
                headers={"Content-Type": "application/json"}
            ) as response:
                response_time = time.time() - start_time
                response_data = await response.json()
                
                print(f"‚úÖ Respuesta recibida en {response_time:.2f} segundos")
                print(f"   - Status code: {response.status}")
                print(f"   - Success: {response_data.get('success')}")
                
                # Verificar que NO es procesamiento as√≠ncrono
                if 'data' in response_data and 'fase_1_triaje' in response_data['data']:
                    print(f"‚úÖ Procesamiento s√≠ncrono confirmado")
                    print(f"   - Resultado completo recibido inmediatamente")
                    
                    # Verificar algunos elementos del resultado
                    data = response_data['data']
                    metricas = data.get('metricas', {})
                    print(f"\nüìä M√©tricas del procesamiento:")
                    print(f"   - Tiempo total: {metricas.get('tiempo_total_segundos', 0):.2f}s")
                    print(f"   - Hechos extra√≠dos: {metricas.get('conteos_elementos', {}).get('hechos_extraidos', 0)}")
                    print(f"   - Entidades extra√≠das: {metricas.get('conteos_elementos', {}).get('entidades_extraidas', 0)}")
                    
                    return True
                    
                elif response_data.get('status') == 'processing':
                    print(f"‚ùå Se detect√≥ procesamiento as√≠ncrono (no esperado)")
                    print(f"   - El art√≠culo peque√±o deber√≠a procesarse s√≠ncronamente")
                    return False
                    
                else:
                    print(f"‚ùå Respuesta inesperada")
                    print(f"   - Data: {json.dumps(response_data, indent=2)}")
                    return False
                    
    except Exception as e:
        print(f"‚ùå Error en test: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Ejecutar todos los tests de procesamiento as√≠ncrono."""
    print("=" * 80)
    print("TEST DE VERIFICACI√ìN DE PROCESAMIENTO AS√çNCRONO")
    print("=" * 80)
    print(f"\nüìç API URL: {API_BASE_URL}")
    print(f"üìè Threshold as√≠ncrono: {ASYNC_PROCESSING_THRESHOLD} caracteres")
    
    # Verificar que el API est√° activa
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{API_BASE_URL}/health") as response:
                if response.status == 200:
                    print(f"‚úÖ API est√° activa y respondiendo")
                else:
                    print(f"‚ùå API no responde correctamente (status: {response.status})")
                    return 1
    except Exception as e:
        print(f"‚ùå No se puede conectar al API: {e}")
        print(f"   Aseg√∫rate de que el servidor est√© ejecut√°ndose en {API_BASE_URL}")
        return 1
    
    # Test 1: Art√≠culo largo as√≠ncrono
    job_id = await test_articulo_largo_async()
    
    if job_id:
        # Esperar y verificar estado del job
        final_status = await check_job_status(job_id)
        if final_status:
            data = final_status.get('data', {})
            if data.get('status') == 'completed':
                print(f"\n‚úÖ Test 1: Test as√≠ncrono exitoso")
            else:
                print(f"\n‚ùå Test 1: Error - Job no complet√≥ exitosamente")
        else:
            print(f"\n‚ùå Test 1: Error - No se pudo verificar estado del job")
    else:
        print(f"\n‚ùå Test 1: Error - No se obtuvo job_id")
    
    # Test 2: M√∫ltiples requests concurrentes
    job_ids = await test_multiples_requests_concurrentes()
    
    if job_ids:
        print(f"\n‚úÖ Test 2: M√∫ltiples requests concurrentes exitoso")
        print(f"   - Se crearon {len(job_ids)} jobs concurrentemente")
    else:
        print(f"\n‚ùå Test 2: Error - No se pudieron crear jobs concurrentes")
    
    # Test 3: Art√≠culo peque√±o s√≠ncrono
    sync_result = await test_articulo_pequeno_sincrono()
    
    if sync_result:
        print(f"\n‚úÖ Test 3: Procesamiento s√≠ncrono verificado")
    else:
        print(f"\n‚ùå Test 3: Error - Procesamiento s√≠ncrono fall√≥")
    
    # Resumen final
    print("\n" + "=" * 80)
    print("RESUMEN DE TESTS")
    print("=" * 80)
    
    test_results = {
        "Test 1 (As√≠ncrono)": job_id is not None,
        "Test 2 (Concurrencia)": len(job_ids) > 0,
        "Test 3 (S√≠ncrono)": sync_result
    }
    
    passed = sum(1 for result in test_results.values() if result)
    total = len(test_results)
    
    for test_name, result in test_results.items():
        status = "‚úÖ PAS√ì" if result else "‚ùå FALL√ì"
        print(f"{test_name}: {status}")
    
    print(f"\nTotal: {passed}/{total} tests pasaron")
    
    if passed == total:
        print("\n‚úÖ ¬°TODOS LOS TESTS PASARON! El procesamiento as√≠ncrono funciona correctamente")
        return 0
    else:
        print(f"\n‚ùå {total - passed} tests fallaron. Revisa los errores arriba.")
        return 1


if __name__ == "__main__":
    # Ejecutar con asyncio
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
